{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":59156,"databundleVersionId":13874099,"sourceType":"competition"},{"sourceId":262477103,"sourceType":"kernelVersion"},{"sourceId":279806245,"sourceType":"kernelVersion"},{"sourceId":281545678,"sourceType":"kernelVersion"}],"dockerImageVersionId":31192,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# MABe Challenge - XGBoost inference Notebook","metadata":{}},{"cell_type":"markdown","source":"ğŸ“ **Note:** Please note that comments and explanations are in Japanese. However, I've made an effort to write clear, self-explanatory code that should be accessible to non-Japanese speakers as well.","metadata":{}},{"cell_type":"markdown","source":"## training notebook: \nhttps://www.kaggle.com/code/hutch1221/mabe-starter-train-ja/notebook","metadata":{}},{"cell_type":"code","source":"!pip install -q --no-index --find-links=/kaggle/input/mabe-package xgboost==3.1.1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T06:10:47.276234Z","iopub.execute_input":"2025-11-25T06:10:47.276447Z","iopub.status.idle":"2025-11-25T06:10:58.945652Z","shell.execute_reply.started":"2025-11-25T06:10:47.276426Z","shell.execute_reply":"2025-11-25T06:10:58.944506Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!cp /kaggle/input/mabe-starter-train-ja/self_features.py .\n!cp /kaggle/input/mabe-starter-train-ja/pair_features.py .\n!cp /kaggle/input/mabe-starter-train-ja/robustify.py .\n!cp -r /kaggle/input/mabe-starter-train-ja/results .","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T06:10:58.948329Z","iopub.execute_input":"2025-11-25T06:10:58.948716Z","iopub.status.idle":"2025-11-25T06:11:12.761563Z","shell.execute_reply.started":"2025-11-25T06:10:58.948672Z","shell.execute_reply":"2025-11-25T06:11:12.760112Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import gc\nimport itertools\nimport re\nimport sys\nfrom collections import defaultdict\nfrom pathlib import Path\n\nimport joblib\nimport numpy as np\nimport pandas as pd\nimport polars as pl\nimport xgboost as xgb\nfrom tqdm.auto import tqdm\n\nsys.path.append(\"/kaggle/usr/lib/mabe-f-beta\")\nfrom metric import score","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-25T06:11:12.777434Z","iopub.execute_input":"2025-11-25T06:11:12.777876Z","iopub.status.idle":"2025-11-25T06:11:14.699477Z","shell.execute_reply.started":"2025-11-25T06:11:12.777828Z","shell.execute_reply":"2025-11-25T06:11:14.698565Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# const\nINPUT_DIR = Path(\"/kaggle/input/MABe-mouse-behavior-detection\")\nTRAIN_TRACKING_DIR = INPUT_DIR / \"train_tracking\"\nTRAIN_ANNOTATION_DIR = INPUT_DIR / \"train_annotation\"\nTEST_TRACKING_DIR = INPUT_DIR / \"test_tracking\"\n\nWORKING_DIR = Path(\"/kaggle/working\")\n\nINDEX_COLS = [\n    \"video_id\",\n    \"agent_mouse_id\",\n    \"target_mouse_id\",\n    \"video_frame\",\n]\n\nBODY_PARTS = [\n    \"ear_left\",\n    \"ear_right\",\n    \"nose\",\n    \"neck\",\n    \"body_center\",\n    \"lateral_left\",\n    \"lateral_right\",\n    \"hip_left\",\n    \"hip_right\",\n    \"tail_base\",\n    \"tail_tip\",\n]\n\nSELF_BEHAVIORS = [\n    \"biteobject\",\n    \"climb\",\n    \"dig\",\n    \"exploreobject\",\n    \"freeze\",\n    \"genitalgroom\",\n    \"huddle\",\n    \"rear\",\n    \"rest\",\n    \"run\",\n    \"selfgroom\",\n]\n\nPAIR_BEHAVIORS = [\n    \"allogroom\",\n    \"approach\",\n    \"attack\",\n    \"attemptmount\",\n    \"avoid\",\n    \"chase\",\n    \"chaseattack\",\n    \"defend\",\n    \"disengage\",\n    \"dominance\",\n    \"dominancegroom\",\n    \"dominancemount\",\n    \"ejaculate\",\n    \"escape\",\n    \"flinch\",\n    \"follow\",\n    \"intromit\",\n    \"mount\",\n    \"reciprocalsniff\",\n    \"shepherd\",\n    \"sniff\",\n    \"sniffbody\",\n    \"sniffface\",\n    \"sniffgenital\",\n    \"submit\",\n    \"tussle\",\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T06:11:14.700546Z","iopub.execute_input":"2025-11-25T06:11:14.701007Z","iopub.status.idle":"2025-11-25T06:11:14.70829Z","shell.execute_reply.started":"2025-11-25T06:11:14.700976Z","shell.execute_reply":"2025-11-25T06:11:14.706886Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import gc\nimport re\nimport ast\nimport sys\nimport warnings\nimport itertools\nfrom pathlib import Path\nfrom dataclasses import dataclass\nfrom typing import Dict, List, Any, Optional\n\nimport numpy as np\nimport pandas as pd\nfrom scipy.ndimage import gaussian_filter1d\nfrom tqdm.auto import tqdm\n\n\nwarnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\nnp.seterr(invalid=\"ignore\", divide=\"ignore\")\n\n@dataclass\nclass FeatureConfig:\n    fps: float = 30.0\n    pix_per_cm: float = 1.0\n    smooth_sigma: float = 1.0\n    use_pairwise: bool = True\n\n@dataclass\nclass AgentContext:\n    idx: pd.Index\n    pos: np.ndarray\n    vel: np.ndarray\n    speed: np.ndarray\n    acc: np.ndarray\n    cx: pd.Series\n    cy: pd.Series\n    speed_series: pd.Series\n    raw_df: Optional[pd.DataFrame] = None\n\nclass FeatureExtractor:\n    \"\"\"\n    Class trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng hÃ nh vi tá»« dá»¯ liá»‡u tracking.\n    \"\"\"\n    def __init__(self, fps: float, pix_per_cm: float, smooth_sigma: float = 1.0, use_pairwise: bool = True):\n        # Map tham sá»‘ tá»« init vÃ o Config\n        self.cfg = FeatureConfig(\n            fps=float(fps), \n            pix_per_cm=float(pix_per_cm), \n            smooth_sigma=smooth_sigma,\n            use_pairwise=use_pairwise\n        )\n        \n        # ÄÄƒng kÃ½ cÃ¡c hÃ m feature sáº½ cháº¡y\n        self.feature_registry = {\n            \"kinematics\": self._feat_basic_kinematics,\n            \"multiscale\": self._feat_multiscale,\n            \"long_range\": self._feat_long_range,\n            \"cumulative\": self._feat_cumulative,\n            \"curvature\": self._feat_curvature,\n            \"speed_asym\": self._feat_speed_asym,\n            \"gauss_shift\": self._feat_gauss_shift,\n            \"grooming\": self._feat_avoidance_trajectory,\n            \"pose\": self._feat_pose_shape,\n            \"a\": self._feat_submission_temporal,\n            \"pose_adv\": self._feat_pose_advanced, \n            \"pairwise\": self._feat_pairwise\n        }\n\n    # --- Helpers ---\n    def _scale(self, n_frames_30fps: int) -> int:\n        \"\"\"Quy Ä‘á»•i sá»‘ frame tá»« chuáº©n 30fps sang fps thá»±c táº¿ cá»§a video.\"\"\"\n        return max(1, int(round(n_frames_30fps * self.cfg.fps / 30.0)))\n\n    def _to_cm(self, arr):\n        \"\"\"Chuyá»ƒn pixel -> cm.\"\"\"\n        return arr / self.cfg.pix_per_cm\n\n    def _smooth(self, x):\n        \"\"\"LÃ m mÆ°á»£t dá»¯ liá»‡u báº±ng Gaussian filter.\"\"\"\n        if self.cfg.smooth_sigma is None or x.shape[0] < 3: return x\n        if np.all(np.isnan(x)): return x\n        return gaussian_filter1d(x, sigma=self.cfg.smooth_sigma, axis=0, mode=\"nearest\")\n\n    def _forward_fill_nan(self, pos):\n        \"\"\"\n        Äiá»n dá»¯ liá»‡u thiáº¿u (NaN) báº±ng giÃ¡ trá»‹ há»£p lá»‡ trÆ°á»›c Ä‘Ã³ (Forward Fill).\n        \"\"\"\n        if np.all(np.isnan(pos)):\n            return np.zeros_like(pos)\n\n        pos_ffill = pos.copy()\n        mask = np.any(~np.isnan(pos_ffill), axis=1)\n        if not mask.any():\n            return np.zeros_like(pos_ffill)\n\n        valid_idx = np.where(mask)[0]\n        first, last = valid_idx[0], valid_idx[-1]\n        pos_ffill[:first] = pos_ffill[first]\n        pos_ffill[last + 1:] = pos_ffill[last]\n        df_temp = pd.DataFrame(pos_ffill)\n        df_temp = df_temp.ffill()\n        return df_temp.to_numpy()\n    \n    def _speed_series(self, cx: pd.Series, cy: pd.Series) -> pd.Series:\n        dx = cx.diff()\n        dy = cy.diff()\n        v = np.hypot(dx, dy).fillna(0.0) * self.cfg.fps\n        return v.astype(\"float32\")\n    \n    def _roll_future_mean(self, s: pd.Series, w: int, min_p: int = 1) -> pd.Series:\n        return s.iloc[::-1].rolling(w, min_periods=min_p).mean().iloc[::-1]\n\n    def _roll_future_var(self, s: pd.Series, w: int, min_p: int = 2) -> pd.Series:\n        return s.iloc[::-1].rolling(w, min_periods=min_p).var().iloc[::-1]\n\n    # --- Core Logic ---\n    def _compute_kinematics(self, pos_px: np.ndarray):\n        \"\"\"\n        TÃ­nh toÃ¡n váº­t lÃ½ cÆ¡ báº£n: Pos(cm), Vel, Speed, Acc.\n        Input: Array [Frames, 2] (pixel).\n        Output: Tuple (pos_cm, vel, speed, acc).\n        \"\"\"\n        pos_ffill = self._forward_fill_nan(pos_px)\n        pos_cm = self._to_cm(pos_ffill.astype(np.float32))\n        pos_cm = self._smooth(pos_cm)                                               # [F, 2]\n\n        dt = 1.0 / self.cfg.fps\n        vel = np.zeros_like(pos_cm, dtype=np.float32)\n        vel[1:] = (pos_cm[1:] - pos_cm[:-1]) / dt                                   # [F, 2: (vx, vy)]\n        speed = np.linalg.norm(vel, axis=1, keepdims=True).astype(np.float32)       # [F, 1]\n\n        acc = np.zeros_like(pos_cm, dtype=np.float32)                          \n        acc[1:] = (vel[1:] - vel[:-1]) / dt                                         # [F, 2:(ax, ay)]\n        return pos_cm.astype(np.float32), vel, speed, acc\n\n    def _build_context(self, frames, pos_px, mouse_df=None) -> AgentContext:\n        \"\"\"\n        Táº¡o AgentContext chá»©a Ä‘áº§y Ä‘á»§ thÃ´ng tin váº­t lÃ½ cá»§a 1 con chuá»™t.\n        \"\"\"\n        p, v, s, a = self._compute_kinematics(pos_px)\n        idx = pd.Index(frames, name=\"frame\")\n        \n        return AgentContext(\n            idx=idx, pos=p, vel=v, speed=s, acc=a, \n            cx=pd.Series(p[:, 0], index=idx), \n            cy=pd.Series(p[:, 1], index=idx), \n            speed_series=pd.Series(s[:, 0], index=idx), \n            raw_df=mouse_df\n        )\n\n    # --- Feature Modules ---\n    def _feat_basic_kinematics(self, ctx: AgentContext, **kwargs) -> Dict:\n        \"\"\"\n        Láº¥y cÃ¡c giÃ¡ trá»‹ thÃ´: tá»a Ä‘á»™ x, y, váº­n tá»‘c vx, vy, tá»‘c Ä‘á»™, gia tá»‘c ax, ay.\n        \"\"\"\n        return {\n            \"a_x\": ctx.pos[:, 0], \"a_y\": ctx.pos[:, 1],\n            \"a_vx\": ctx.vel[:, 0], \"a_vy\": ctx.vel[:, 1],\n            \"a_speed\": ctx.speed[:, 0],\n            \"a_ax\": ctx.acc[:, 0], \"a_ay\": ctx.acc[:, 1]\n        }\n\n    def _feat_multiscale(self, ctx: AgentContext, **kwargs) -> Dict:\n        \"\"\"\n        TÃ­nh tá»‘c Ä‘á»™ trung bÃ¬nh (Mean) vÃ  Ä‘á»™ lá»‡ch chuáº©n (Std) á»Ÿ Ä‘a má»©c thá»i gian.\n        Feature 'sp_ratio' Ä‘o Ä‘á»™ bÃ¹ng ná»• (Burstiness).\n        \"\"\"\n        feats = {}\n        speed = ctx.speed_series\n        frame_scales = [10, 40, 160]\n        for scale in frame_scales:\n            ws = self._scale(scale)\n            if len(speed) >= ws:\n                roller = speed.rolling(ws, min_periods=max(1, ws//4), center=True)\n                feats[f\"sp_m{scale}\"] = roller.mean().astype(\"float32\")\n                feats[f\"sp_s{scale}\"] = roller.std().astype(\"float32\")\n        feats[f\"sp_ratio\"] = feats[\"sp_m10\"] / (feats[\"sp_m160\"] + 1e-6)\n        return feats \n        \n    def _feat_long_range(self, ctx: AgentContext, **kwargs) -> Dict:\n        \"\"\"\n        Äáº·c trÆ°ng ngá»¯ cáº£nh dÃ i háº¡n:\n        - x_ml, y_ml: Vá»‹ trÃ­ trung bÃ¬nh trong quÃ¡ khá»©.\n        - sp_pct: Xáº¿p háº¡ng (percentile) cá»§a tá»‘c Ä‘á»™ hiá»‡n táº¡i so vá»›i quÃ¡ khá»©.\n        \"\"\"\n        feats: Dict[str, pd.Series] = {}\n        speed = ctx.speed_series\n\n        for window in [120, 240]:\n            ws = self._scale(window)\n            if len(ctx.cx) >= ws:\n                feats[f\"x_ml{window}\"] = ctx.cx.rolling(ws, min_periods=max(5, ws // 6), center=True).mean()\n                feats[f\"y_ml{window}\"] = ctx.cy.rolling(ws, min_periods=max(5, ws // 6), center=True).mean()\n\n        for span in [60, 120]:\n            s = self._scale(span)\n            feats[f\"x_e{span}\"] = ctx.cx.ewm(span=s, min_periods=1).mean()\n            feats[f\"y_e{span}\"] = ctx.cy.ewm(span=s, min_periods=1).mean()\n\n        for window in [60, 120]:\n            ws = self._scale(window)\n            if len(speed) >= ws:\n                feats[f\"sp_pct{window}\"] = speed.rolling(\n                    ws, min_periods=max(5, ws // 6), center=True\n                ).rank(pct=True)\n        return feats\n    \n\n    def _feat_curvature(self, ctx: AgentContext, **kwargs) -> Dict:\n        feats = {}\n\n        vel_x, vel_y = ctx.vel[:, 0], ctx.vel[:, 1]\n        acc_x, acc_y = ctx.acc[:, 0], ctx.acc[:, 1]\n        cross_prod = vel_x * acc_y - vel_y * acc_x\n        vel_mag = np.sqrt(vel_x**2 + vel_y**2)\n        moving_mask = vel_mag > 2.0\n        vel_mag_safe = np.maximum(vel_mag, 0.1 / self.cfg.fps)\n        raw_curv = cross_prod / (vel_mag_safe**3)\n        raw_curv = np.where(moving_mask, raw_curv, 0.0)\n        min_turn_radius_cm = 0.5\n        max_k = 1.0 / min_turn_radius_cm\n        raw_curv = np.clip(raw_curv, -max_k, max_k)\n        abs_curv = np.abs(raw_curv)\n        abs_curv_series = pd.Series(abs_curv, index=ctx.idx)\n\n        for w in [30, 60]:\n            ws = self._scale(w)\n            min_p = max(ws // 3, 1)\n            feats[f\"curv_mean_{w}\"] = abs_curv_series.rolling(ws, min_periods=min_p).mean()\n\n        angle = np.arctan2(vel_y, vel_x)\n        angle_series = pd.Series(angle, index=ctx.idx)\n        angle_change = np.abs(angle_series.diff().fillna(0.0))\n        angle_change = np.where(angle_change > np.pi, 2 * np.pi - angle_change, angle_change)\n        angle_change_series = pd.Series(angle_change, index=ctx.idx)\n        angle_change_series = pd.Series(np.where(moving_mask, angle_change_series, 0.0), index=ctx.idx)\n\n        ws = self._scale(30)\n        feats[\"turn_rate_30\"] = angle_change_series.rolling(ws, min_periods=max(ws // 3, 1)).sum()\n\n        return feats\n    \n    def _feat_cumulative(self, ctx: AgentContext, **kwargs) -> Dict:\n        \"\"\"\n        Tá»•ng quÃ£ng Ä‘Æ°á»ng di chuyá»ƒn trong má»™t khoáº£ng thá»i gian dÃ i xung quanh frame hiá»‡n táº¡i.\n        \"\"\"\n        feats = {}\n        L = max(1, self._scale(180))\n        step = np.hypot(ctx.cx.diff(), ctx.cy.diff()).fillna(0.0)\n        path = step.rolling(2 * L + 1, min_periods=max(5, L // 6), center=True).sum()\n        feats[\"path_cum180\"] =  path.fillna(0.0).astype(\"float32\")\n        return feats\n\n    def _feat_speed_asym(self, ctx: AgentContext, **kwargs) -> Dict:\n        \"\"\"\n        Báº¥t Ä‘á»‘i xá»©ng tá»‘c Ä‘á»™ (TÆ°Æ¡ng lai - QuÃ¡ khá»©).\n        \"\"\"\n        w = max(3, self._scale(30))\n        v = ctx.speed_series\n        v_past = v.rolling(w, min_periods=1).mean()\n        v_fut = self._roll_future_mean(v, w, min_p=1)\n        return {\"spd_asym_1s\": (v_fut - v_past).fillna(0.0)}\n    \n    def _feat_gauss_shift(self, ctx: AgentContext, **kwargs) -> Dict:\n        \"\"\"\n        Äá»™ lá»‡ch Gaussian (KL Divergence) giá»¯a quÃ¡ khá»© vÃ  tÆ°Æ¡ng lai.\n        Äo lÆ°á»ng sá»± thay Ä‘á»•i tráº¡ng thÃ¡i thá»‘ng kÃª.\n        \"\"\"\n        w = max(5, self._scale(30))\n        v = ctx.speed_series\n        mu_p = v.rolling(w, min_periods=1).mean()\n        va_p = v.rolling(w, min_periods=1).var().clip(lower=1e-6)\n        mu_f = self._roll_future_mean(v, w, min_p=1)\n        va_f = self._roll_future_var(v, w, min_p=1).clip(lower=1e-6)\n\n        kl_pf = 0.5 * (\n            (va_p / va_f) + ((mu_f - mu_p) ** 2) / va_f - 1.0 + np.log(va_f / va_p)\n        )\n        kl_fp = 0.5 * (\n            (va_f / va_p) + ((mu_p - mu_f) ** 2) / va_p - 1.0 + np.log(va_p / va_f)\n        )\n        return {\n            \"spd_symkl_1s\": (kl_pf + kl_fp).replace([np.inf, -np.inf], np.nan).fillna(0.0)\n        }\n\n    def _feat_avoidance_trajectory(self, ctx: AgentContext, target_ctx: AgentContext = None, **kwargs) -> Dict[str, pd.Series]:\n        \"\"\"\n        TÃ­nh toÃ¡n quá»¹ Ä‘áº¡o nÃ© trÃ¡nh:\n        1. Relative Heading: GÃ³c di chuyá»ƒn so vá»›i hÆ°á»›ng tá»›i Ä‘á»‘i thá»§.\n        2. Future Distance Gain: Dá»± bÃ¡o xem hÃ nh Ä‘á»™ng nÃ y cÃ³ giÃºp chuá»™t ra xa Ä‘á»‘i thá»§ trong tÆ°Æ¡ng lai khÃ´ng.\n        \"\"\"\n        feats = {}\n        if target_ctx is None: \n            return feats\n\n        idx = ctx.idx\n        def zero(): return pd.Series(0.0, index=idx, dtype=\"float32\")\n\n        # --- 1. RELATIVE HEADING (GÃ³c lá»‡ch hÆ°á»›ng Ä‘i) ---\n        # Vector tá»« TÃ´i -> Äá»‹ch\n        rel_vec = target_ctx.pos - ctx.pos\n        # GÃ³c hÆ°á»›ng tá»›i Ä‘á»‹ch (Angle to Target)\n        angle_to_target = np.arctan2(rel_vec[:, 1], rel_vec[:, 0])\n        \n        # GÃ³c di chuyá»ƒn cá»§a TÃ´i (My Heading)\n        my_heading = np.arctan2(ctx.vel[:, 1], ctx.vel[:, 0])\n        \n        # Äá»™ lá»‡ch gÃ³c (Absolute Difference)\n        # Cáº§n xá»­ lÃ½ wrap gÃ³c (vÃ­ dá»¥: lá»‡ch giá»¯a 179 Ä‘á»™ vÃ  -179 Ä‘á»™ lÃ  2 Ä‘á»™ chá»© ko pháº£i 358)\n        diff = np.abs(angle_to_target - my_heading)\n        diff = np.minimum(diff, 2*np.pi - diff) # Chuáº©n hÃ³a vá» [0, pi]\n        \n        # Feature: Cosine cá»§a gÃ³c lá»‡ch\n        # 1.0 (0 Ä‘á»™) -> Lao vÃ o\n        # 0.0 (90 Ä‘á»™) -> AVOID (LÃ¡ch ngang)\n        # -1.0 (180 Ä‘á»™) -> Escape\n        feats[\"heading_rel_cos\"] = pd.Series(np.cos(diff), index=idx, dtype=\"float32\")\n        \n        # Feature: GÃ³c lá»‡ch tuyá»‡t Ä‘á»‘i (Ä‘á»•i ra Ä‘á»™ cho dá»… hÃ¬nh dung náº¿u cáº§n, á»Ÿ Ä‘Ã¢y Ä‘á»ƒ rad)\n        feats[\"heading_rel_abs\"] = pd.Series(diff, index=idx, dtype=\"float32\")\n\n\n        # --- 2. FUTURE DISTANCE GAIN (Hiá»‡u quáº£ trÃ¡nh nÃ©) ---\n        # \"Sau 15 frame (0.5s) hoáº·c 30 frame (1s), mÃ¬nh cÃ³ xa nÃ³ ra khÃ´ng?\"\n        \n        dist_now = np.linalg.norm(rel_vec, axis=1)\n        s_dist = pd.Series(dist_now, index=idx)\n        \n        scales = [15, 30] # 0.5s vÃ  1s\n        for w in scales:\n            ws = self._scale(w)\n            \n            # Láº¥y khoáº£ng cÃ¡ch á»Ÿ tÆ°Æ¡ng lai (shift ngÆ°á»£c lÃªn)\n            # s.shift(-ws) lÃ  giÃ¡ trá»‹ cá»§a t + ws\n            dist_future = s_dist.shift(-ws)\n            gain = dist_future - s_dist\n            \n            feats[f\"dist_gain_{w}f\"] = gain.fillna(0.0).astype(\"float32\")\n\n        return feats\n    \n    def _extract_part(self, ctx: AgentContext, part: str) -> Optional[np.ndarray]:\n        if ctx.raw_df is None: return None\n        if part not in ctx.raw_df.columns.get_level_values(0): return None\n        try:\n            sub_df = ctx.raw_df.xs(part, axis=1, level=0)[[\"x\", \"y\"]].reindex(ctx.idx)\n        except KeyError: return None\n        raw = sub_df.to_numpy()\n        raw = self._forward_fill_nan(raw)\n        cm = self._to_cm(raw.astype(np.float32))\n        return self._smooth(cm)\n    \n    def _extract_parts_dict(self, ctx: AgentContext, parts: List[str] = None) -> Dict[str, Optional[np.ndarray]]:\n        out = {}\n        for p in parts:\n            out[p] = self._extract_part(ctx, p)\n        return out\n        \n    def _feat_pose_shape(self, ctx: AgentContext, **kwargs) -> Dict:\n        \"\"\"\n        Placeholder cho cÃ¡c Ä‘áº·c trÆ°ng hÃ¬nh dÃ¡ng (Elongation, Body Angle...).\n        \"\"\"\n        feats = {}\n\n        def zero(): return pd.Series(0.0, index=ctx.idx, dtype=\"float32\")\n\n        def dist(k1, k2):\n            p1, p2 = parts.get(k1), parts.get(k2)\n            if p1 is None or p2 is None: return zero()\n            d = np.linalg.norm(p1 - p2, axis=1)\n            return pd.Series(d, index=ctx.idx, dtype=\"float32\")\n        \n        def body_angle():\n            if parts.get(\"nose\") is None: return zero()\n            if parts.get(\"body_center\") is None: return zero()\n            if parts.get(\"tail_base\") is None: return zero()\n\n            v1 = parts.get(\"nose\") - parts.get(\"body_center\")\n            v2 = parts.get(\"tail_base\") - parts.get(\"body_center\")\n            dot_product = np.sum(v1 * v2, axis=1)\n            mag = np.linalg.norm(v1, axis=1) * np.linalg.norm(v2, axis=1)\n            cos_angle = np.clip(dot_product / (mag + 1e-6), -1.0, 1.0).astype(\"float32\")\n            return cos_angle\n        \n        def elongation():\n            if parts.get(\"nose\")          is None: return zero()\n            if parts.get(\"tail_base\")     is None: return zero()\n            if parts.get(\"lateral_left\")  is None: return zero()\n            if parts.get(\"lateral_right\") is None: return zero()\n\n            d1 = dist(\"nose\", \"tail_base\")\n            d2 = dist(\"lateral_left\", \"lateral_right\")\n            elongation = d1 / (d2 + 1e-6).astype(\"float32\")\n            return elongation\n        \n        def vel(part: str, n_frames_30fps: int) -> Dict:\n            part_pos = self._extract_part(ctx, part)\n            if part_pos is None: return zero()\n            \n            s_x = pd.Series(part_pos[:, 0], index=ctx.idx)\n            s_y = pd.Series(part_pos[:, 1], index=ctx.idx)\n            raw_speed = self._speed_series(s_x, s_y)\n\n            ws = self._scale(n_frames_30fps)\n            val = raw_speed.rolling(ws, min_periods=1, center=True).mean()\n            return val.astype(\"float32\")\n\n\n        target_parts = [\"nose\", \"neck\", \"body_center\", \"tail_base\", \n                        \"ear_left\", \"ear_right\", \n                        \"lateral_left\", \"lateral_right\", \"tail_midpoint\", \"tail_tip\"]\n        \n        parts = self._extract_parts_dict(ctx, target_parts)\n\n        feats[\"a_body_width\"]                = dist(\"lateral_left\", \"lateral_right\")\n        feats[\"aa_nose_bodycenter_dist\"]     = dist(\"nose\", \"body_center\")\n        feats[\"aa_nose_tailbase_dist\"]       = dist(\"nose\", \"tail_base\")\n        feats[\"aa_bodycenter_tailbase_dist\"] = dist(\"body_center\", \"tail_base\")\n        \n        feats[\"aa_bodycenter_ear_l_dist\"]    = dist(\"body_center\", \"ear_left\")\n        feats[\"aa_bodycenter_ear_r_dist\"]    = dist(\"body_center\", \"ear_right\")\n        feats[\"aa_bodycenter_lateral_l_dist\"]= dist(\"body_center\", \"lateral_left\")\n        feats[\"aa_bodycenter_lateral_r_dist\"]= dist(\"body_center\", \"lateral_right\")\n        \n        feats[\"a_body_angle\"]                = body_angle()\n        feats[\"a_elongation\"]                = elongation()\n        feats[\"a_tail_base_vel_500ms\"]       = vel(\"tail_base\", 15)\n        feats[\"a_tail_base_vel_1000ms\"]      = vel(\"tail_base\", 30)\n        feats[\"a_tail_base_vel_2000ms\"]      = vel(\"tail_base\", 60)\n        feats[\"a_tail_base_vel_3000ms\"]      = vel(\"tail_base\", 90)\n        feats[\"a_nose_vel_500ms\"]            = vel(\"nose\", 15)\n        feats[\"a_nose_vel_1000ms\"]           = vel(\"nose\", 30)\n        feats[\"a_nose_vel_2000ms\"]           = vel(\"nose\", 60)\n        feats[\"a_nose_vel_3000ms\"]           = vel(\"nose\", 90)\n        feats[\"a_ear_right_vel_500ms\"]       = vel(\"ear_right\", 15)\n        feats[\"a_ear_right_vel_1000ms\"]      = vel(\"ear_right\", 30)\n        feats[\"a_ear_right_vel_2000ms\"]      = vel(\"ear_right\", 60)\n        feats[\"a_ear_right_vel_3000ms\"]      = vel(\"ear_right\", 90)\n        # len_1 = dist(\"tail_base\", \"tail_midpoint\")\n        # len_2 = dist(\"tail_midpoint\", \"tail_tip\")\n        # len_full = dist(\"tail_base\", \"tail_tip\")\n        # feats[\"tail_curl\"] = ((len_1 + len_2) / (len_full + 1e-6)).astype(\"float32\")\n        return feats\n\n    def _feat_submission_temporal(self, ctx: AgentContext, target_ctx: AgentContext = None, **kwargs) -> Dict[str, pd.Series]:\n        \"\"\"\n        Äáº·c trÆ°ng 'KÃ½ á»©c sá»£ hÃ£i' (Fear Memory) Ä‘á»ƒ báº¯t Submit tÄ©nh.\n        GiÃºp phÃ¢n biá»‡t Submit (sau khi bá»‹ Ä‘Ã¡nh) vs Rest (bÃ¬nh yÃªn).\n        \"\"\"\n        feats = {}\n        if target_ctx is None: return feats\n        \n        idx = ctx.idx\n        \n        # --- 1. XÃ‚Y Dá»°NG TÃN HIá»†U XUNG Äá»˜T Gá»C (RAW CONFLICT SIGNAL) ---\n        # Conflict = (NÃ³ nhanh) * (NÃ³ hÆ°á»›ng vá» tÃ´i) * (á» gáº§n)\n        \n        # A. NÃ³ hÆ°á»›ng vá» tÃ´i khÃ´ng? (Gaze Cosine)\n        # Vector ná»‘i TÃ´i -> NÃ³\n        vec_to_target = target_ctx.pos - ctx.pos\n        dist = np.linalg.norm(vec_to_target, axis=1)\n        dist_safe = pd.Series(dist, index=idx).replace(0, 1e-6)\n        \n        # Vector váº­n tá»‘c cá»§a NÃ³\n        t_vel = target_ctx.vel\n        \n        # Dot product: Váº­n tá»‘c NÃ³ . Vector hÆ°á»›ng vá» TÃ´i (NgÆ°á»£c dáº¥u vá»›i vec_to_target)\n        # vec_target_to_me = -vec_to_target\n        # dot > 0 nghÄ©a lÃ  nÃ³ Ä‘ang lao vá» phÃ­a tÃ´i\n        dot_threat = np.sum(t_vel * (-vec_to_target), axis=1)\n        \n        # Threat Score tá»©c thá»i (cm/s hÆ°á»›ng vá» náº¡n nhÃ¢n)\n        # Chá»‰ tÃ­nh khi nÃ³ láº¡i gáº§n (< 15cm)\n        threat_raw = (dot_threat / dist_safe).clip(lower=0) \n        threat_raw = threat_raw * (dist_safe < 15.0).astype(float)\n        threat_series = pd.Series(threat_raw, index=idx, dtype=\"float32\")\n\n        # --- 2. KÃ á»¨C Sá»¢ HÃƒI (FEAR MEMORY - QUAN TRá»ŒNG NHáº¤T) ---\n        # DÃ¹ng Rolling Max Ä‘á»ƒ \"kÃ©o dÃ i\" ná»—i sá»£.\n        # Náº¿u 2 giÃ¢y trÆ°á»›c nÃ³ lao vÃ o tÃ´i, thÃ¬ giá» tÃ´i váº«n Ä‘ang sá»£.\n        \n        # Cá»­a sá»• 3 giÃ¢y (90 frames)\n        ws_memory = self._scale(90)\n        \n        # Fear Level = Max threat trong 3 giÃ¢y qua\n        feats[\"fear_memory_3s\"] = threat_series.rolling(ws_memory, min_periods=1).max().astype(\"float32\")\n\n        # --- 3. TRáº NG THÃI SUBMIT (Káº¾T Há»¢P) ---\n        # Submit = (TÃ´i Ä‘ang Ä‘á»©ng yÃªn) * (TÃ´i Ä‘ang co cá»¥m) * (TÃ´i Ä‘ang sá»£)\n        \n        # TÃ´i Ä‘á»©ng yÃªn (< 1 cm/s)\n        my_speed = ctx.speed_series\n        is_still = (my_speed < 1.0).astype(float)\n        \n        # TÃ´i co cá»¥m (DÃ¹ng a_elongation tháº¥p hoáº·c body_width/length cao)\n        # Giáº£ sá»­ báº¡n Ä‘Ã£ tÃ­nh a_elongation á»Ÿ hÃ m pose (tháº¥p lÃ  co cá»¥m)\n        # Náº¿u chÆ°a cÃ³ thÃ¬ dÃ¹ng táº¡m logic: elongation < 1.2\n        # á» Ä‘Ã¢y mÃ¬nh táº¡o feature giáº£ láº­p Ä‘á»™ co cá»¥m náº¿u chÆ°a cÃ³\n        parts = self._extract_parts_dict(ctx, [\"nose\", \"tail_base\"])\n        if parts[\"nose\"] is not None:\n            spine_len = np.linalg.norm(parts[\"nose\"] - parts[\"tail_base\"], axis=1)\n            is_compact = (spine_len < 8.0).astype(float) # VÃ­ dá»¥ chuá»™t dÃ i < 8cm lÃ  co\n            is_compact = pd.Series(is_compact, index=idx)\n        else:\n            is_compact = pd.Series(0.0, index=idx)\n\n        # FINAL SCORE\n        # ÄÃ¢y lÃ  feature Ä‘á»‹nh danh cho Submit tÄ©nh\n        feats[\"static_submit_prob\"] = (\n            is_still * is_compact * feats[\"fear_memory_3s\"]\n        ).astype(\"float32\")\n\n        return feats\n\n    def _feat_pose_advanced(self, ctx: AgentContext, **kwargs) -> Dict[str, pd.Series]:\n        feats = {}\n        idx = ctx.idx\n        def zero(): return pd.Series(0.0, index=idx, dtype=\"float32\")\n        \n        # 1. TRÃCH XUáº¤T Dá»® LIá»†U\n        # NhÃ³m cÆ¡ báº£n\n        parts = self._extract_parts_dict(ctx, [\"nose\", \"neck\", \"body_center\", \"tail_base\", \n                                               \"lateral_left\", \"lateral_right\", \n                                               \"tail_midpoint\", \"tail_tip\"])\n        \n        # NhÃ³m Headpiece (Láº¥y Ä‘áº¡i diá»‡n 4 gÃ³c trÃªn Ä‘á»ƒ tÃ­nh toÃ¡n cho nháº¹)\n        hp_parts = self._extract_parts_dict(ctx, [\n            \"headpiece_topfrontleft\", \"headpiece_topfrontright\",\n            \"headpiece_topbackleft\", \"headpiece_topbackright\"\n        ])\n\n        # Helper tÃ­nh khoáº£ng cÃ¡ch\n        def dist(p1, p2):\n            if p1 is None or p2 is None: return zero()\n            return pd.Series(np.linalg.norm(p1 - p2, axis=1), index=idx, dtype=\"float32\")\n        \n        # 2. Spine Length (Neck -> TailBase) - Key cho Rear\n        feats[\"a_spine_len\"] = dist(parts[\"neck\"], parts[\"tail_base\"])\n\n        # --- B. HEADPIECE ORIENTATION (GÃ³c nhÃ¬n 3D) ---\n        # ÄÃ¢y lÃ  feature Ä‘á»™c quyá»n cá»§a dataset nÃ y\n        \n        fl = hp_parts[\"headpiece_topfrontleft\"]\n        fr = hp_parts[\"headpiece_topfrontright\"]\n        bl = hp_parts[\"headpiece_topbackleft\"]\n        br = hp_parts[\"headpiece_topbackright\"]\n        \n        if fl is not None and br is not None:\n            # 1. Head Length 2D (Front to Back)\n            # Trung Ä‘iá»ƒm Front\n            front_mid = (fl + fr) / 2\n            back_mid = (bl + br) / 2\n            head_len_2d = np.linalg.norm(front_mid - back_mid, axis=1)\n            \n            # Náº¿u head_len_2d ngáº¯n láº¡i -> Äáº§u Ä‘ang ngáº©ng lÃªn hoáº·c cÃºi xuá»‘ng (Pitch)\n            # (Giáº£ sá»­ chiá»u dÃ i tháº­t cá»§a headpiece lÃ  háº±ng sá»‘ Max quan sÃ¡t Ä‘Æ°á»£c)\n            feats[\"head_pitch_proxy\"] = pd.Series(head_len_2d, index=idx, dtype=\"float32\")\n            \n            # 2. Head Roll (Äá»™ nghiÃªng)\n            # So sÃ¡nh Ä‘Æ°á»ng chÃ©o: (FrontLeft-BackRight) vs (FrontRight-BackLeft)\n            d1 = np.linalg.norm(fl - br, axis=1)\n            d2 = np.linalg.norm(fr - bl, axis=1)\n            feats[\"head_roll_proxy\"] = pd.Series(np.abs(d1 - d2), index=idx, dtype=\"float32\")\n        else:\n            feats[\"head_pitch_proxy\"] = zero()\n            feats[\"head_roll_proxy\"] = zero()\n\n        # --- C. TAIL DYNAMICS (ÄuÃ´i) ---\n        \n        # 1. Tail Straightness (ÄuÃ´i tháº³ng hay cong?)\n        # (Base->Mid) + (Mid->Tip)\n        len_1 = dist(parts[\"tail_base\"], parts[\"tail_midpoint\"])\n        len_2 = dist(parts[\"tail_midpoint\"], parts[\"tail_tip\"])\n        len_full = dist(parts[\"tail_base\"], parts[\"tail_tip\"])\n        \n        # Ratio: Náº¿u = 1.0 lÃ  tháº³ng táº¯p. Lá»›n hÆ¡n 1.0 lÃ  cong.\n        feats[\"tail_curl\"] = ((len_1 + len_2) / (len_full + 1e-6)).astype(\"float32\")\n        \n        # 2. Tail Tip Speed (Äá»™ quáº¥t Ä‘uÃ´i - Aggression)\n        # TÃ­nh riÃªng váº­n tá»‘c mÅ©i Ä‘uÃ´i\n        if parts[\"tail_tip\"] is not None:\n            tip_pos = parts[\"tail_tip\"]\n            s_x = pd.Series(tip_pos[:, 0], index=idx)\n            s_y = pd.Series(tip_pos[:, 1], index=idx)\n            # Láº¥y rung Ä‘á»™ng táº§n sá»‘ cao (cá»­a sá»• nhá» 15 frames)\n            raw_speed = self._speed_series(s_x, s_y)\n            feats[\"tail_tip_speed_fast\"] = raw_speed.rolling(self._scale(15), center=True).mean().astype(\"float32\")\n        else:\n            feats[\"tail_tip_speed_fast\"] = zero()\n\n        return feats\n\n\n    def _feat_pairwise(self, ctx: AgentContext, target_ctx: AgentContext = None, **kwargs) -> Dict:\n        \"\"\"\n        Äáº·c trÆ°ng tÆ°Æ¡ng tÃ¡c cáº·p Ä‘Ã´i (Pairwise): Khoáº£ng cÃ¡ch, Tá»‘c Ä‘á»™ tiáº¿p cáº­n.\n        \"\"\"\n        feats: Dict[str, pd.Series] = {}\n        if target_ctx is None: \n            return feats\n\n        idx = ctx.idx\n        def zero(): return pd.Series(0.0, index=idx, dtype=\"float32\")\n\n        # --- 1. KHOáº¢NG CÃCH CÆ  Báº¢N (DISTANCES) ---\n        # Vector ná»‘i Agent -> Target\n        rel_vec = target_ctx.pos - ctx.pos\n        dist = np.linalg.norm(rel_vec, axis=1)\n        feats[\"rel_dist\"] = pd.Series(dist, index=idx, dtype=\"float32\")\n\n        # --- 2. KHOáº¢NG CÃCH CHI TIáº¾T (NOSE-TO-PART) ---\n        # Láº¥y cÃ¡c bá»™ pháº­n quan trá»ng\n        my_parts = self._extract_parts_dict(ctx, [\"nose\", \"neck\"])\n        target_parts = self._extract_parts_dict(target_ctx, \n            [\"nose\", \"tail_base\", \"body_center\", \"ear_left\", \"ear_right\", \n             \"lateral_left\", \"lateral_right\", \"tail_midpoint\"])\n\n        def dist_ab(pt_a, pt_b):\n            if pt_a is None or pt_b is None: return zero()\n            d = np.linalg.norm(pt_a - pt_b, axis=1)\n            return pd.Series(d, index=idx, dtype=\"float32\")\n\n        an, tn = my_parts[\"nose\"], target_parts[\"nose\"]\n        feats[\"dist_nose_nose\"] = dist_ab(an, tn)\n        feats[\"dist_nose_tail\"] = dist_ab(an, target_parts[\"tail_base\"])\n        feats[\"dist_nose_body\"] = dist_ab(an, target_parts[\"body_center\"])\n        feats[\"dist_nose_el\"]   = dist_ab(an, target_parts[\"ear_left\"])\n        feats[\"dist_nose_er\"]   = dist_ab(an, target_parts[\"ear_right\"])\n        feats[\"dist_nose_tll\"]  = dist_ab(an, target_parts[\"lateral_left\"])\n        feats[\"dist_nose_tlr\"]  = dist_ab(an, target_parts[\"lateral_right\"])\n        feats[\"dist_nose_tmp\"]  = dist_ab(an, target_parts[\"tail_midpoint\"])\n\n        # --- 3. Äá»ŠNH HÆ¯á»šNG & GÃ“C NHÃŒN (ORIENTATION & GAZE) ---\n        # Helper láº¥y vector cÆ¡ thá»ƒ (MÅ©i - ÄuÃ´i/ThÃ¢n)\n        def get_body_vec(parts_dict):\n            head = parts_dict.get(\"nose\")\n            # Æ¯u tiÃªn Ä‘uÃ´i, náº¿u ko cÃ³ thÃ¬ dÃ¹ng thÃ¢n\n            tail = parts_dict.get(\"tail_base\")\n            if tail is None: tail = parts_dict.get(\"body_center\") # Fallback\n            \n            if head is not None and tail is not None:\n                return head - tail\n            return None\n\n        a_vec = get_body_vec(my_parts)\n        t_vec = get_body_vec(target_parts)\n\n        # A. Body Cosine: Hai con cÃ¹ng chiá»u hay ngÆ°á»£c chiá»u?\n        if a_vec is not None and t_vec is not None:\n            dot = np.sum(a_vec * t_vec, axis=1)\n            mags = np.linalg.norm(a_vec, axis=1) * np.linalg.norm(t_vec, axis=1)\n            feats[\"body_cosine\"] = pd.Series(\n                np.clip(dot / (mags + 1e-6), -1.0, 1.0), index=idx, dtype=\"float32\"\n            )\n        else:\n            feats[\"body_cosine\"] = zero()\n\n        # B. Gaze Cosine: TÃ´i cÃ³ Ä‘ang nhÃ¬n vá» phÃ­a Target khÃ´ng?\n        # Vector Ã¡nh nhÃ¬n = Target_Pos - My_Pos = rel_vec\n        if a_vec is not None:\n            dot_gaze = np.sum(a_vec * rel_vec, axis=1)\n            mag_a = np.linalg.norm(a_vec, axis=1)\n            # dist Ä‘Ã£ tÃ­nh á»Ÿ bÆ°á»›c 1\n            feats[\"gaze_cosine\"] = pd.Series(\n                np.clip(dot_gaze / (mag_a * dist + 1e-6), -1.0, 1.0),\n                index=idx, dtype=\"float32\"\n            )\n        else:\n            feats[\"gaze_cosine\"] = zero()\n\n        # --- 4. PHÃ‚N RÃƒ Váº¬N Tá»C (VELOCITY DECOMPOSITION) - CHÃŒA KHÃ“A CHO AVOID/ESCAPE ---\n        # Vector Ä‘Æ¡n vá»‹ hÆ°á»›ng vá» Ä‘á»‹ch (u)\n        dist_safe = dist.copy()\n        dist_safe[dist_safe == 0] = 1e-6\n        u_vec = rel_vec / dist_safe[:, None]\n\n        # a_vel vÃ  t_vel láº¥y tá»« Context\n        a_vel, t_vel = ctx.vel, target_ctx.vel\n\n        # A. Approach Speed (Váº­n tá»‘c dá»c trá»¥c ná»‘i 2 con)\n        # DÆ°Æ¡ng: Lao vÃ o nhau | Ã‚m: Cháº¡y ra xa nhau\n        a_along = np.sum(a_vel * u_vec, axis=1)\n        t_along = np.sum(t_vel * (-u_vec), axis=1) # Target hÆ°á»›ng ngÆ°á»£c láº¡i\n        rel_along = np.sum((a_vel - t_vel) * u_vec, axis=1)\n\n        # B. Lateral Speed (Váº­n tá»‘c ngang - VuÃ´ng gÃ³c trá»¥c ná»‘i)\n        # Vector chiáº¿u: v_proj = (v . u) * u\n        a_proj = a_along[:, None] * u_vec\n        a_lat_vec = a_vel - a_proj\n        a_lat_speed = np.linalg.norm(a_lat_vec, axis=1)\n\n        feats[\"approach_speed_agent\"]  = pd.Series(a_along, index=idx, dtype=\"float32\")\n        feats[\"approach_speed_target\"] = pd.Series(t_along, index=idx, dtype=\"float32\")\n        feats[\"approach_speed_rel\"]    = pd.Series(rel_along, index=idx, dtype=\"float32\")\n        feats[\"lateral_speed_agent\"]   = pd.Series(a_lat_speed, index=idx, dtype=\"float32\")\n        return feats\n\n\n    # --- Methods tÆ°Æ¡ng thÃ­ch ---\n    \n    def build_pose_tensor(self, tracking: pd.DataFrame):\n        \"\"\"\n        Chuyá»ƒn dá»¯ liá»‡u tracking (DataFrame) sang Tensor [Frames, Mice, 2] vÃ  Dict chi tiáº¿t.\n        \"\"\"\n        tracking = tracking.sort_values(\"video_frame\")\n        frames = np.sort(tracking[\"video_frame\"].unique())\n        \n        pvid = tracking.pivot(\n            index=\"video_frame\", \n            columns=[\"mouse_id\", \"bodypart\"], \n            values=[\"x\", \"y\"]\n        )\n        pvid = pvid.reorder_levels([1, 2, 0], axis=1).sort_index(axis=1).astype(\"float32\")\n        mouse_ids = list(pvid.columns.get_level_values(0).unique())\n        pos = np.full((len(frames), len(mouse_ids), 2), np.nan, dtype=np.float32)\n        per_mouse_df = {}\n        \n        for i, mid in enumerate(mouse_ids):\n            single = pvid[mid]\n            per_mouse_df[mid] = single\n            \n            if \"body_center\" in single.columns.get_level_values(0):\n                cx = single[\"body_center\"][\"x\"]\n                cy = single[\"body_center\"][\"y\"]\n            else:\n                cx = single.xs(\"x\", level=1, axis=1).mean(axis=1)\n                cy = single.xs(\"y\", level=1, axis=1).mean(axis=1)\n            \n            pos[:, i, 0] = cx.reindex(frames).values\n            pos[:, i, 1] = cy.reindex(frames).values\n            \n        return frames, mouse_ids, pos, per_mouse_df\n\n    def extract_agent_target(\n        self, \n        frames: np.ndarray, \n        mouse_ids: List[Any], \n        pos: np.ndarray, \n        agent_id: Any, \n        target_id: Any, \n        per_mouse_df: Dict = None\n    ) -> pd.DataFrame:\n        \"\"\"\n        TrÃ­ch xuáº¥t Ä‘áº·c trÆ°ng cho cáº·p (Agent, Target).\n        \"\"\"\n        try:\n            aid_idx = mouse_ids.index(agent_id)\n        except ValueError:\n            return pd.DataFrame() \n\n        # 1. Build Agent Context\n        ctx_agent = self._build_context(\n            frames, \n            pos[:, aid_idx, :], \n            per_mouse_df.get(agent_id) if per_mouse_df else None\n        )\n\n        # 2. Build Target Context\n        ctx_target = None\n        if self.cfg.use_pairwise and target_id is not None and target_id in mouse_ids:\n             tid_idx = mouse_ids.index(target_id)\n             ctx_target = self._build_context(\n                 frames, \n                 pos[:, tid_idx, :], \n                 per_mouse_df.get(target_id) if per_mouse_df else None\n             )\n\n        # 3. Run all features\n        all_data = {}\n        for func_name, func in self.feature_registry.items():\n            out_dict = func(ctx_agent, target_ctx=ctx_target)\n            all_data.update(out_dict)\n\n        df_out = pd.DataFrame(all_data, index=ctx_agent.idx)\n        df_out = df_out.replace([np.inf, -np.inf], np.nan).fillna(0.0)\n        \n        return df_out.reindex(sorted(df_out.columns), axis=1)\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# read data\ntest_dataframe = pl.read_csv(INPUT_DIR / \"test.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T06:11:14.709357Z","iopub.execute_input":"2025-11-25T06:11:14.709708Z","iopub.status.idle":"2025-11-25T06:11:14.770483Z","shell.execute_reply.started":"2025-11-25T06:11:14.709667Z","shell.execute_reply":"2025-11-25T06:11:14.769816Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# preprocess behavior labels\ntest_behavior_dataframe = (\n    test_dataframe.filter(pl.col(\"behaviors_labeled\").is_not_null())\n    .select(\n        pl.col(\"lab_id\"),\n        pl.col(\"video_id\"),\n        pl.col(\"behaviors_labeled\").map_elements(eval, return_dtype=pl.List(pl.Utf8)).alias(\"behaviors_labeled_list\"),\n    )\n    .explode(\"behaviors_labeled_list\")\n    .rename({\"behaviors_labeled_list\": \"behaviors_labeled_element\"})\n    .select(\n        pl.col(\"lab_id\"),\n        pl.col(\"video_id\"),\n        pl.col(\"behaviors_labeled_element\").str.split(\",\").list[0].str.replace_all(\"'\", \"\").alias(\"agent\"),\n        pl.col(\"behaviors_labeled_element\").str.split(\",\").list[1].str.replace_all(\"'\", \"\").alias(\"target\"),\n        pl.col(\"behaviors_labeled_element\").str.split(\",\").list[2].str.replace_all(\"'\", \"\").alias(\"behavior\"),\n    )\n)\n\ntest_self_behavior_dataframe = test_behavior_dataframe.filter(pl.col(\"behavior\").is_in(SELF_BEHAVIORS))\ntest_pair_behavior_dataframe = test_behavior_dataframe.filter(pl.col(\"behavior\").is_in(PAIR_BEHAVIORS))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T06:11:14.772668Z","iopub.execute_input":"2025-11-25T06:11:14.772907Z","iopub.status.idle":"2025-11-25T06:11:14.92444Z","shell.execute_reply.started":"2025-11-25T06:11:14.772888Z","shell.execute_reply":"2025-11-25T06:11:14.923746Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%run -i self_features.py\n%run -i pair_features.py\n%run -i robustify.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T06:11:14.925246Z","iopub.execute_input":"2025-11-25T06:11:14.925489Z","iopub.status.idle":"2025-11-25T06:11:14.937149Z","shell.execute_reply.started":"2025-11-25T06:11:14.925468Z","shell.execute_reply":"2025-11-25T06:11:14.936161Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"(WORKING_DIR / \"self_features\").mkdir(exist_ok=True, parents=True)\n(WORKING_DIR / \"pair_features\").mkdir(exist_ok=True, parents=True)\n\nrows = test_dataframe.rows(named=True)\n\nfor row in tqdm(rows, total=len(rows)):\n    lab_id = row[\"lab_id\"]\n    video_id = row[\"video_id\"]\n\n    tracking_path = TEST_TRACKING_DIR / f\"{lab_id}/{video_id}.parquet\"\n    tracking = pl.read_parquet(tracking_path)\n\n    self_features = make_self_features(metadata=row, tracking=tracking)\n    pair_features = make_pair_features(metadata=row, tracking=tracking)\n\n    self_features.write_parquet(WORKING_DIR / \"self_features\" / f\"{video_id}.parquet\")\n    pair_features.write_parquet(WORKING_DIR / \"pair_features\" / f\"{video_id}.parquet\")\n\n    del self_features, pair_features\n    gc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T06:11:14.938231Z","iopub.execute_input":"2025-11-25T06:11:14.938578Z","iopub.status.idle":"2025-11-25T06:11:17.322433Z","shell.execute_reply.started":"2025-11-25T06:11:14.938544Z","shell.execute_reply":"2025-11-25T06:11:17.321288Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# submissionãƒ‡ãƒ¼ã‚¿ä½œæˆ","metadata":{}},{"cell_type":"code","source":"# å„ã‚°ãƒ«ãƒ¼ãƒ—ï¼ˆlab_id, video_id, agent, target ã®çµ„ã¿åˆã‚ã›ï¼‰ã”ã¨ã®äºˆæ¸¬çµæœã‚’æ ¼ç´ã™ã‚‹ãƒªã‚¹ãƒˆ\ngroup_submissions = []\n\n# ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ lab_id, video_id, agent, target ã§ã‚°ãƒ«ãƒ¼ãƒ—åŒ–\n# maintain_order=True ã§å…ƒã®é †åºã‚’ä¿æŒ\ngroups = list(test_behavior_dataframe.group_by(\"lab_id\", \"video_id\", \"agent\", \"target\", maintain_order=True))\n\n# å„ã‚°ãƒ«ãƒ¼ãƒ—ã«å¯¾ã—ã¦é †ç•ªã«å‡¦ç†ã‚’å®Ÿè¡Œï¼ˆé€²æ—ãƒãƒ¼ã‚’è¡¨ç¤ºï¼‰\nfor (lab_id, video_id, agent, target), group in tqdm(groups, total=len(list(groups))):\n    # agentï¼ˆè¡Œå‹•ã‚’èµ·ã“ã™ãƒã‚¦ã‚¹ï¼‰ã®ID ã‚’æŠ½å‡º\n    # ä¾‹: \"mouse1\" â†’ 1\n    agent_mouse_id = int(re.search(r\"mouse(\\d+)\", agent).group(1))\n    \n    # targetï¼ˆè¡Œå‹•ã®å¯¾è±¡ï¼‰ã®ID ã‚’æŠ½å‡º\n    # \"self\"ï¼ˆè‡ªå·±è¡Œå‹•ï¼‰ã®å ´åˆã¯ -1ã€ãã‚Œä»¥å¤–ã¯ãƒã‚¦ã‚¹IDã‚’æŠ½å‡º\n    # ä¾‹: \"mouse2\" â†’ 2, \"self\" â†’ -1\n    target_mouse_id = -1 if target == \"self\" else int(re.search(r\"mouse(\\d+)\", target).group(1))\n\n    # ===== ç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ =====\n    if target == \"self\":\n        # è‡ªå·±è¡Œå‹•ï¼ˆrear ãªã©ï¼‰ã®å ´åˆ: self_features ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰èª­ã¿è¾¼ã¿\n        \n        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åˆ—ï¼ˆvideo_id, agent_mouse_id, video_frame ãªã©ï¼‰ã‚’èª­ã¿è¾¼ã¿\n        index = (\n            pl.scan_parquet(WORKING_DIR / \"self_features\" / f\"{video_id}.parquet\")\n            .filter((pl.col(\"agent_mouse_id\") == agent_mouse_id))  # å¯¾è±¡ãƒã‚¦ã‚¹ã§ãƒ•ã‚£ãƒ«ã‚¿\n            .select(INDEX_COLS)  # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åˆ—ã®ã¿é¸æŠ\n            .collect()  # é…å»¶è©•ä¾¡ã‚’å®Ÿè¡Œã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—\n        )\n        \n        # ç‰¹å¾´é‡åˆ—ï¼ˆé€Ÿåº¦ã€è·é›¢ã€è§’åº¦ãªã©ï¼‰ã‚’èª­ã¿è¾¼ã¿\n        feature = (\n            pl.scan_parquet(WORKING_DIR / \"self_features\" / f\"{video_id}.parquet\")\n            .filter((pl.col(\"agent_mouse_id\") == agent_mouse_id))\n            .select(pl.exclude(INDEX_COLS))  # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åˆ—ä»¥å¤–ã‚’é¸æŠ\n            .collect()\n        )\n    else:\n        # ãƒšã‚¢è¡Œå‹•ï¼ˆattack, chase ãªã©ï¼‰ã®å ´åˆ: pair_features ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰èª­ã¿è¾¼ã¿\n        \n        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åˆ—ã‚’èª­ã¿è¾¼ã¿ï¼ˆagent ã¨ target ã®ä¸¡æ–¹ã§ãƒ•ã‚£ãƒ«ã‚¿ï¼‰\n        index = (\n            pl.scan_parquet(WORKING_DIR / \"pair_features\" / f\"{video_id}.parquet\")\n            .filter((pl.col(\"agent_mouse_id\") == agent_mouse_id) & (pl.col(\"target_mouse_id\") == target_mouse_id))\n            .select(INDEX_COLS)\n            .collect()\n        )\n        \n        # ç‰¹å¾´é‡åˆ—ã‚’èª­ã¿è¾¼ã¿\n        feature = (\n            pl.scan_parquet(WORKING_DIR / \"pair_features\" / f\"{video_id}.parquet\")\n            .filter((pl.col(\"agent_mouse_id\") == agent_mouse_id) & (pl.col(\"target_mouse_id\") == target_mouse_id))\n            .select(pl.exclude(INDEX_COLS))\n            .collect()\n        )\n\n    # äºˆæ¸¬çµæœã‚’æ ¼ç´ã™ã‚‹ DataFrame ã‚’ä½œæˆï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åˆ—ã®ã‚³ãƒ”ãƒ¼ï¼‰\n    prediction_dataframe = index.clone()\n\n    # ===== å„è¡Œå‹•ï¼ˆbehaviorï¼‰ã«å¯¾ã—ã¦äºˆæ¸¬ã‚’å®Ÿè¡Œ =====\n    for row in group.rows(named=True):\n        behavior = row[\"behavior\"]  # ç¾åœ¨ã®è¡Œå‹•åï¼ˆä¾‹: \"attack\", \"rear\"ï¼‰\n\n        # å„ foldï¼ˆäº¤å·®æ¤œè¨¼ã®åˆ†å‰²ï¼‰ã®äºˆæ¸¬çµæœã‚’æ ¼ç´ã™ã‚‹ãƒªã‚¹ãƒˆ\n        predictions = []  # äºˆæ¸¬ç¢ºç‡\n        prediction_labels = []  # äºˆæ¸¬ãƒ©ãƒ™ãƒ«ï¼ˆé–¾å€¤ã§ 0/1 ã«å¤‰æ›ã—ãŸã‚‚ã®ï¼‰\n\n        # ä¿å­˜ã•ã‚ŒãŸ fold ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å–å¾—\n        # ä¾‹: results/AdaptableSnail/attack/fold_0, fold_1, fold_2\n        fold_dirs = list((WORKING_DIR / \"results\" / lab_id / behavior).glob(\"fold_*\"))\n        if not fold_dirs:\n            # è¨“ç·´ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—\n            continue\n\n        # å„ fold ã®ãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬ã‚’å®Ÿè¡Œ\n        for fold_dir in fold_dirs:\n            # ä¿å­˜ã•ã‚ŒãŸæœ€é©é–¾å€¤ã‚’èª­ã¿è¾¼ã¿\n            with open(fold_dir / \"threshold.txt\", \"r\") as f:\n                threshold = float(f.read().strip())\n            \n            # XGBoost ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿\n            model = xgb.Booster(model_file=fold_dir / \"model.json\")\n            \n            # ç‰¹å¾´é‡ã‚’ XGBoost ã®å…¥åŠ›å½¢å¼ï¼ˆDMatrixï¼‰ã«å¤‰æ›\n            dtest = xgb.DMatrix(feature, feature_names=feature.columns)\n            \n            # ãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬ã‚’å®Ÿè¡Œï¼ˆç¢ºç‡å€¤ã‚’å–å¾—ï¼‰\n            fold_predictions = model.predict(dtest)\n            \n            # äºˆæ¸¬ç¢ºç‡ã‚’ä¿å­˜\n            predictions.append(fold_predictions)\n            \n            # é–¾å€¤ã‚’é©ç”¨ã—ã¦ãƒ©ãƒ™ãƒ«åŒ–ï¼ˆ1: è¡Œå‹•ã‚ã‚Š, 0: è¡Œå‹•ãªã—ï¼‰\n            prediction_labels.append((fold_predictions >= threshold).astype(np.int8))\n\n        # äºˆæ¸¬çµæœã‚’ DataFrame ã«è¿½åŠ \n        # å„ fold ã®ã€Œäºˆæ¸¬ç¢ºç‡ Ã— äºˆæ¸¬ãƒ©ãƒ™ãƒ«ã€ã‚’åˆ—ã¨ã—ã¦è¿½åŠ \n        # ï¼ˆãƒ©ãƒ™ãƒ«ãŒ 0 ã®å ´åˆã¯ç¢ºç‡ã‚‚ 0 ã«ãªã‚Šã€1 ã®å ´åˆã¯ç¢ºç‡ãŒãã®ã¾ã¾æ®‹ã‚‹ï¼‰\n        prediction_dataframe = prediction_dataframe.with_columns(\n            *[\n                pl.Series(name=f\"{behavior}_{fold}\", values=predictions[fold] * prediction_labels[fold], dtype=pl.Float32)\n                for fold in range(len(fold_dirs))\n            ]\n        )\n\n    # ===== æœ€ã‚‚ç¢ºç‡ãŒé«˜ã„è¡Œå‹•ã‚’é¸æŠ =====\n    \n    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åˆ—ä»¥å¤–ã®åˆ—åã‚’å–å¾—ï¼ˆå„è¡Œå‹•ã®äºˆæ¸¬åˆ—ï¼‰\n    cols = prediction_dataframe.select(pl.exclude(INDEX_COLS)).columns\n    if not cols:\n        # äºˆæ¸¬åˆ—ãŒ 1 ã¤ã‚‚ãªã„å ´åˆã¯è­¦å‘Šã‚’è¡¨ç¤ºã—ã¦ã‚¹ã‚­ãƒƒãƒ—\n        tqdm.write(f\"Warning: No predictions found for {lab_id}, {video_id}, {agent}, {target}\")\n        continue\n\n    # å„ãƒ•ãƒ¬ãƒ¼ãƒ ã§æœ€ã‚‚ç¢ºç‡ãŒé«˜ã„è¡Œå‹•ã‚’é¸æŠ\n    prediction_labels_dataframe = prediction_dataframe.with_columns(\n        pl.struct(pl.col(cols))  # å…¨äºˆæ¸¬åˆ—ã‚’æ§‹é€ ä½“ã«ã¾ã¨ã‚ã‚‹\n        .map_elements(\n            # å„è¡Œï¼ˆãƒ•ãƒ¬ãƒ¼ãƒ ï¼‰ã«å¯¾ã—ã¦ä»¥ä¸‹ã®å‡¦ç†ã‚’å®Ÿè¡Œ:\n            # - ã™ã¹ã¦ã®äºˆæ¸¬å€¤ãŒ 0 ãªã‚‰ \"none\"ï¼ˆè¡Œå‹•ãªã—ï¼‰\n            # - ãã‚Œä»¥å¤–ã¯æœ€å¤§å€¤ã‚’æŒã¤è¡Œå‹•åã‚’è¿”ã™\n            lambda row: \"none\" if sum(row.values()) == 0 else (cols[np.argmax(list(row.values()))]).split(\"_\")[0],\n            return_dtype=pl.String,\n        )\n        .alias(\"prediction\")  # æ–°ã—ã„åˆ—åã‚’ \"prediction\" ã¨ã™ã‚‹\n    ).select(INDEX_COLS + [\"prediction\"])  # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åˆ—ã¨äºˆæ¸¬åˆ—ã®ã¿é¸æŠ\n\n    # ===== é€£ç¶šã™ã‚‹åŒã˜è¡Œå‹•ã‚’ã‚¤ãƒ™ãƒ³ãƒˆã«ã¾ã¨ã‚ã‚‹ =====\n    \n    group_submission = (\n        prediction_labels_dataframe\n        .filter((pl.col(\"prediction\") != pl.col(\"prediction\").shift(1)))  # è¡Œå‹•ãŒå¤‰åŒ–ã—ãŸãƒ•ãƒ¬ãƒ¼ãƒ ã®ã¿æ®‹ã™\n        .with_columns(pl.col(\"video_frame\").shift(-1).alias(\"stop_frame\"))  # æ¬¡ã®å¤‰åŒ–ç‚¹ã‚’çµ‚äº†ãƒ•ãƒ¬ãƒ¼ãƒ ã¨ã™ã‚‹\n        .filter(pl.col(\"prediction\") != \"none\")  # \"none\"ï¼ˆè¡Œå‹•ãªã—ï¼‰ã‚’é™¤å¤–\n        .select(\n            # æå‡ºå½¢å¼ã«åˆã‚ã›ã¦åˆ—ã‚’é¸æŠãƒ»å¤‰æ›\n            pl.col(\"video_id\"),\n            (\"mouse\" + pl.col(\"agent_mouse_id\").cast(str)).alias(\"agent_id\"),  # ä¾‹: 1 â†’ \"mouse1\"\n            pl.when(pl.col(\"target_mouse_id\") == -1)  # target_mouse_id ãŒ -1 ãªã‚‰\n            .then(pl.lit(\"self\"))  # \"self\" ã«å¤‰æ›\n            .otherwise(\"mouse\" + pl.col(\"target_mouse_id\").cast(str))  # ãã‚Œä»¥å¤–ã¯ \"mouseN\"\n            .alias(\"target_id\"),\n            pl.col(\"prediction\").alias(\"action\"),  # è¡Œå‹•å\n            pl.col(\"video_frame\").alias(\"start_frame\"),  # é–‹å§‹ãƒ•ãƒ¬ãƒ¼ãƒ \n            pl.col(\"stop_frame\"),  # çµ‚äº†ãƒ•ãƒ¬ãƒ¼ãƒ \n        )\n    )\n\n    # ã“ã®ã‚°ãƒ«ãƒ¼ãƒ—ã®æå‡ºãƒ‡ãƒ¼ã‚¿ã‚’ãƒªã‚¹ãƒˆã«è¿½åŠ \n    group_submissions.append(group_submission)\n\n# ===== å…¨ã‚°ãƒ«ãƒ¼ãƒ—ã®äºˆæ¸¬çµæœã‚’çµåˆ =====\n\n# å…¨ã‚°ãƒ«ãƒ¼ãƒ—ã®æå‡ºãƒ‡ãƒ¼ã‚¿ã‚’ç¸¦æ–¹å‘ã«çµåˆ\nsubmission = pl.concat(group_submissions, how=\"vertical\").sort(\n    \"video_id\",\n    \"agent_id\",\n    \"target_id\",\n    \"action\",\n    \"start_frame\",\n    \"stop_frame\",\n)\n\n# æå‡ºãƒ‡ãƒ¼ã‚¿ã®å …ç‰¢åŒ–å‡¦ç†ï¼ˆé‡è¤‡å‰Šé™¤ã€ãƒ•ãƒ¬ãƒ¼ãƒ ã®ä¿®æ­£ãªã©ï¼‰\nsubmission = robustify(submission, test_dataframe, train_test=\"test\")\n\n# è¡Œç•ªå·ï¼ˆrow_idï¼‰ã‚’è¿½åŠ ã—ã¦ CSV ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜\nsubmission.with_row_index(\"row_id\").write_csv(WORKING_DIR / \"submission.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T06:11:17.323571Z","iopub.execute_input":"2025-11-25T06:11:17.323877Z","iopub.status.idle":"2025-11-25T06:12:00.49198Z","shell.execute_reply.started":"2025-11-25T06:11:17.323844Z","shell.execute_reply":"2025-11-25T06:12:00.491069Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!head submission.csv","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T06:12:00.49305Z","iopub.execute_input":"2025-11-25T06:12:00.49368Z","iopub.status.idle":"2025-11-25T06:12:00.638771Z","shell.execute_reply.started":"2025-11-25T06:12:00.493646Z","shell.execute_reply":"2025-11-25T06:12:00.637905Z"}},"outputs":[],"execution_count":null}]}