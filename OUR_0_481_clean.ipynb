{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a117035a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import gc\n",
    "import json\n",
    "import warnings\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "import lightgbm as lgb\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Any, Optional\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "# --- Cấu hình & Đường dẫn ---\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "np.seterr(invalid=\"ignore\", divide=\"ignore\")\n",
    "\n",
    "INPUT_DIR = Path(\"/kaggle/input/MABe-mouse-behavior-detection\")\n",
    "TRAIN_TRACKING_DIR = INPUT_DIR / \"train_tracking\"\n",
    "TEST_TRACKING_DIR = INPUT_DIR / \"test_tracking\"\n",
    "WORKING_DIR = Path(\"/kaggle/working\")\n",
    "WORKING_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Định nghĩa các hành vi\n",
    "SELF_BEHAVIORS = [\"biteobject\", \"climb\", \"dig\", \"exploreobject\", \"freeze\", \"genitalgroom\", \"huddle\", \"rear\", \"rest\", \"run\", \"selfgroom\"]\n",
    "PAIR_BEHAVIORS = [\"allogroom\", \"approach\", \"attack\", \"attemptmount\", \"avoid\", \"chase\", \"chaseattack\", \"defend\", \"disengage\", \"dominance\", \"dominancegroom\", \"dominancemount\", \"ejaculate\", \"escape\", \"flinch\", \"follow\", \"intromit\", \"mount\", \"reciprocalsniff\", \"shepherd\", \"sniff\", \"sniffbody\", \"sniffface\", \"sniffgenital\", \"submit\", \"tussle\"]\n",
    "\n",
    "# --- MAPPING---\n",
    "# 4 Lab dùng bộ results-ensemble-optuna (0->3)\n",
    "# Các Lab còn lại dùng results-xgb-fe\n",
    "LAB_RESULT_DIR_MAP = {\n",
    "    \"AdaptableSnail\":   Path(\"/kaggle/input/results-ensemble-optuna\"),   # 0\n",
    "    \"BoisterousParrot\": Path(\"/kaggle/input/results-ensemble-optuna1\"),  # 1\n",
    "    \"NiftyGoldfinch\":   Path(\"/kaggle/input/results-ensemble-optuna2\"),  # 2\n",
    "    \"TranquilPanther\":  Path(\"/kaggle/input/results-ensemble-optuna3\"),  # 3\n",
    "}\n",
    "DEFAULT_RESULT_DIR = Path(\"/kaggle/input/results-xgb-fe\")\n",
    "\n",
    "TARGET_LABS = [\n",
    "    \"AdaptableSnail\", \"BoisterousParrot\", \"NiftyGoldfinch\", \"TranquilPanther\",\n",
    "    \"ElegantMink\", \"GroovyShrew\", \"JovialSwallow\", \"PleasantMeerkat\", \"SparklingTapir\"\n",
    "]\n",
    "\n",
    "# =============================================================================\n",
    "# 1. CORE: FEATURE EXTRACTOR\n",
    "# =============================================================================\n",
    "# =============================================================================\n",
    "# 1. CORE: FEATURE EXTRACTOR (FULL VERSION)\n",
    "# =============================================================================\n",
    "@dataclass\n",
    "class AgentContext:\n",
    "    idx: pd.Index\n",
    "    pos: np.ndarray        # [F, 2] cm\n",
    "    vel: np.ndarray        # [F, 2] cm/s\n",
    "    speed: np.ndarray      # [F, 1] cm/s\n",
    "    acc: np.ndarray        # [F, 2] cm/s^2\n",
    "    cx: pd.Series          # Series tọa độ X\n",
    "    cy: pd.Series          # Series tọa độ Y\n",
    "    speed_series: pd.Series\n",
    "    raw_df: Optional[pd.DataFrame] = None \n",
    "\n",
    "class FeatureExtractor:\n",
    "    def __init__(self, fps: float, pix_per_cm: float, smooth_sigma: float = 1.0, use_pairwise: bool = True):\n",
    "        self.cfg = FeatureConfig(float(fps), float(pix_per_cm), smooth_sigma, use_pairwise)\n",
    "        \n",
    "        self.feature_registry = {\n",
    "            \"kinematics\": self._feat_basic_kinematics,\n",
    "            \"multiscale\": self._feat_multiscale,\n",
    "            \"long_range\": self._feat_long_range,\n",
    "            \"cumulative\": self._feat_cumulative,\n",
    "            \"curvature\": self._feat_curvature,\n",
    "            \"speed_asym\": self._feat_speed_asym,\n",
    "            \"gauss_shift\": self._feat_gauss_shift,\n",
    "            \"avoid\": self._feat_avoidance_trajectory,\n",
    "            \"pose\": self._feat_pose_shape,\n",
    "            \"pairwise\": self._feat_pairwise,\n",
    "            \"follow\": self._feat_follow_pattern,\n",
    "            \"short\": self._feat_shortburst_social,   # (cho attack/chase)\n",
    "            \"climb\": self._feat_climb,               # (cho ElegantMink/GroovyShrew)\n",
    "            \"ejac\": self._feat_ejaculate_temporal, \n",
    "            \"submit\": self._feat_submission_temporal,\n",
    "            \"atk_sniff\": self._feat_attack_sniff     # (IoU, jerk)\n",
    "        }\n",
    "\n",
    "    # --- Helpers ---\n",
    "    def _scale(self, n_frames_30fps: int) -> int:\n",
    "        return max(1, int(round(n_frames_30fps * self.cfg.fps / 30.0)))\n",
    "\n",
    "    def _to_cm(self, arr):\n",
    "        return arr / self.cfg.pix_per_cm\n",
    "\n",
    "    def _smooth(self, x):\n",
    "        if self.cfg.smooth_sigma is None or x.shape[0] < 3: return x\n",
    "        if np.all(np.isnan(x)): return x\n",
    "        return gaussian_filter1d(x, sigma=self.cfg.smooth_sigma, axis=0, mode=\"nearest\")\n",
    "\n",
    "    def _forward_fill_nan(self, pos):\n",
    "        if np.all(np.isnan(pos)): return np.zeros_like(pos)\n",
    "        mask = np.any(~np.isnan(pos), axis=1)\n",
    "        if not mask.any(): return np.zeros_like(pos)\n",
    "        pos_ffill = pos.copy()\n",
    "        df_temp = pd.DataFrame(pos_ffill)\n",
    "        return df_temp.ffill().bfill().to_numpy() # ffill then bfill for edges\n",
    "\n",
    "    def _speed_series(self, cx: pd.Series, cy: pd.Series) -> pd.Series:\n",
    "        dx, dy = cx.diff(), cy.diff()\n",
    "        return (np.hypot(dx, dy).fillna(0.0) * self.cfg.fps).astype(\"float32\")\n",
    "\n",
    "    def _roll_future_mean(self, s: pd.Series, w: int, min_p: int = 1) -> pd.Series:\n",
    "        return s.iloc[::-1].rolling(w, min_periods=min_p).mean().iloc[::-1]\n",
    "\n",
    "    def _roll_future_var(self, s: pd.Series, w: int, min_p: int = 2) -> pd.Series:\n",
    "        return s.iloc[::-1].rolling(w, min_periods=min_p).var().iloc[::-1]\n",
    "\n",
    "    def _extract_part(self, ctx: AgentContext, part: str) -> Optional[np.ndarray]:\n",
    "        if ctx.raw_df is None: return None\n",
    "        if part not in ctx.raw_df.columns.get_level_values(0): return None\n",
    "        try:\n",
    "            sub_df = ctx.raw_df.xs(part, axis=1, level=0)[[\"x\", \"y\"]].reindex(ctx.idx)\n",
    "        except KeyError: return None\n",
    "        \n",
    "        raw = sub_df.to_numpy()\n",
    "        raw = self._forward_fill_nan(raw)\n",
    "        cm = self._to_cm(raw.astype(np.float32))\n",
    "        return self._smooth(cm)\n",
    "\n",
    "    def _extract_parts_dict(self, ctx: AgentContext, parts: List[str]) -> Dict[str, Optional[np.ndarray]]:\n",
    "        out = {}\n",
    "        for p in parts:\n",
    "            out[p] = self._extract_part(ctx, p)\n",
    "        return out\n",
    "\n",
    "    # --- Core Logic ---\n",
    "    def _compute_kinematics(self, pos_px: np.ndarray):\n",
    "        pos_cm = self._smooth(self._to_cm(self._forward_fill_nan(pos_px).astype(np.float32)))\n",
    "        dt = 1.0 / self.cfg.fps\n",
    "        vel = np.zeros_like(pos_cm, dtype=np.float32)\n",
    "        vel[1:] = (pos_cm[1:] - pos_cm[:-1]) / dt\n",
    "        speed = np.linalg.norm(vel, axis=1, keepdims=True).astype(np.float32)\n",
    "        acc = np.zeros_like(pos_cm, dtype=np.float32)\n",
    "        acc[1:] = (vel[1:] - vel[:-1]) / dt\n",
    "        return pos_cm.astype(np.float32), vel, speed, acc\n",
    "\n",
    "    def _build_context(self, frames, pos_px, mouse_df=None) -> AgentContext:\n",
    "        p, v, s, a = self._compute_kinematics(pos_px)\n",
    "        idx = pd.Index(frames, name=\"frame\")\n",
    "        return AgentContext(idx, p, v, s, a, \n",
    "                            pd.Series(p[:,0], index=idx), pd.Series(p[:,1], index=idx), \n",
    "                            pd.Series(s[:,0], index=idx), mouse_df)\n",
    "\n",
    "    # =========================================================================\n",
    "    # FULL FEATURES IMPLEMENTATION\n",
    "    # =========================================================================\n",
    "\n",
    "    def _feat_basic_kinematics(self, ctx: AgentContext, **kwargs) -> Dict:\n",
    "        return {\n",
    "            \"a_x\": ctx.pos[:, 0], \"a_y\": ctx.pos[:, 1],\n",
    "            \"a_vx\": ctx.vel[:, 0], \"a_vy\": ctx.vel[:, 1],\n",
    "            \"a_speed\": ctx.speed[:, 0],\n",
    "            \"a_ax\": ctx.acc[:, 0], \"a_ay\": ctx.acc[:, 1]\n",
    "        }\n",
    "\n",
    "    def _feat_multiscale(self, ctx: AgentContext, **kwargs) -> Dict:\n",
    "        feats = {}\n",
    "        for scale in [10, 40, 160]:\n",
    "            ws = self._scale(scale)\n",
    "            if len(ctx.speed_series) >= ws:\n",
    "                r = ctx.speed_series.rolling(ws, min_periods=max(1, ws//4), center=True)\n",
    "                feats[f\"sp_m{scale}\"] = r.mean().astype(\"float32\")\n",
    "                feats[f\"sp_s{scale}\"] = r.std().astype(\"float32\")\n",
    "        if \"sp_m10\" in feats and \"sp_m160\" in feats:\n",
    "            feats[\"sp_ratio\"] = feats[\"sp_m10\"] / (feats[\"sp_m160\"] + 1e-6)\n",
    "        return feats\n",
    "\n",
    "    def _feat_long_range(self, ctx: AgentContext, **kwargs) -> Dict:\n",
    "        feats = {}\n",
    "        for w in [120, 240]:\n",
    "            ws = self._scale(w)\n",
    "            feats[f\"x_ml{w}\"] = ctx.cx.rolling(ws, min_periods=max(5, ws//6), center=True).mean()\n",
    "            feats[f\"y_ml{w}\"] = ctx.cy.rolling(ws, min_periods=max(5, ws//6), center=True).mean()\n",
    "        for w in [60, 120]:\n",
    "            ws = self._scale(w)\n",
    "            feats[f\"sp_pct{w}\"] = ctx.speed_series.rolling(ws, min_periods=max(5, ws//6), center=True).rank(pct=True)\n",
    "        return feats\n",
    "\n",
    "    def _feat_cumulative(self, ctx: AgentContext, **kwargs) -> Dict:\n",
    "        L = max(1, self._scale(180))\n",
    "        step = np.hypot(ctx.cx.diff(), ctx.cy.diff()).fillna(0.0)\n",
    "        return {\"path_cum180\": step.rolling(2*L+1, min_periods=max(5, L//6), center=True).sum().fillna(0.0).astype(\"float32\")}\n",
    "\n",
    "    def _feat_curvature(self, ctx: AgentContext, **kwargs) -> Dict:\n",
    "        vx, vy = ctx.vel[:, 0], ctx.vel[:, 1]\n",
    "        ax, ay = ctx.acc[:, 0], ctx.acc[:, 1]\n",
    "        v_mag = np.maximum(np.hypot(vx, vy), 0.1/self.cfg.fps)\n",
    "        curv = (vx*ay - vy*ax) / (v_mag**3)\n",
    "        curv = np.clip(curv * (v_mag > 2.0), -2.0, 2.0)\n",
    "        s_curv = pd.Series(np.abs(curv), index=ctx.idx)\n",
    "        feats = {}\n",
    "        for w in [30, 60]:\n",
    "            feats[f\"curv_mean_{w}\"] = s_curv.rolling(self._scale(w), min_periods=1).mean()\n",
    "        \n",
    "        # Turn rate\n",
    "        angle = np.arctan2(vy, vx)\n",
    "        angle_change = np.abs(pd.Series(angle, index=ctx.idx).diff().fillna(0.0))\n",
    "        angle_change = np.where(angle_change > np.pi, 2*np.pi - angle_change, angle_change)\n",
    "        ws = self._scale(30)\n",
    "        feats[\"turn_rate_30\"] = pd.Series(angle_change * (v_mag > 0.5), index=ctx.idx).rolling(ws, min_periods=1).sum()\n",
    "        return feats\n",
    "\n",
    "    def _feat_speed_asym(self, ctx: AgentContext, **kwargs) -> Dict:\n",
    "        w = max(3, self._scale(30))\n",
    "        v = ctx.speed_series\n",
    "        return {\"spd_asym_1s\": (self._roll_future_mean(v, w) - v.rolling(w, min_periods=1).mean()).fillna(0.0)}\n",
    "\n",
    "    def _feat_gauss_shift(self, ctx: AgentContext, **kwargs) -> Dict:\n",
    "        w = max(5, self._scale(30))\n",
    "        v = ctx.speed_series\n",
    "        mu_p, va_p = v.rolling(w, min_periods=1).mean(), v.rolling(w, min_periods=1).var().clip(1e-6)\n",
    "        mu_f, va_f = self._roll_future_mean(v, w), self._roll_future_var(v, w).clip(1e-6)\n",
    "        kl = 0.5 * ((va_p/va_f) + ((mu_f-mu_p)**2)/va_f - 1 + np.log(va_f/va_p) + (va_f/va_p) + ((mu_p-mu_f)**2)/va_p - 1 + np.log(va_p/va_f))\n",
    "        return {\"spd_symkl_1s\": kl.replace([np.inf, -np.inf], np.nan).fillna(0.0)}\n",
    "\n",
    "    def _feat_avoidance_trajectory(self, ctx: AgentContext, target_ctx: AgentContext=None, **kwargs) -> Dict:\n",
    "        if target_ctx is None: return {}\n",
    "        rel_vec = target_ctx.pos - ctx.pos\n",
    "        ang_target = np.arctan2(rel_vec[:,1], rel_vec[:,0])\n",
    "        ang_self = np.arctan2(ctx.vel[:,1], ctx.vel[:,0])\n",
    "        diff = np.abs(ang_target - ang_self)\n",
    "        diff = np.minimum(diff, 2*np.pi - diff)\n",
    "        \n",
    "        feats = {\n",
    "            \"heading_rel_cos\": pd.Series(np.cos(diff), index=ctx.idx, dtype=\"float32\"),\n",
    "            \"heading_rel_abs\": pd.Series(diff, index=ctx.idx, dtype=\"float32\")\n",
    "        }\n",
    "        s_dist = pd.Series(np.linalg.norm(rel_vec, axis=1), index=ctx.idx)\n",
    "        for w in [15, 30]:\n",
    "            ws = self._scale(w)\n",
    "            feats[f\"dist_gain_{w}f\"] = (s_dist.shift(-ws) - s_dist).fillna(0.0).astype(\"float32\")\n",
    "        return feats\n",
    "\n",
    "    def _feat_pose_shape(self, ctx: AgentContext, **kwargs) -> Dict:\n",
    "        feats = {}\n",
    "        def zero(): return pd.Series(0.0, index=ctx.idx, dtype=\"float32\")\n",
    "        \n",
    "        target_parts = [\"nose\", \"neck\", \"body_center\", \"tail_base\", \"ear_left\", \"ear_right\", \"lateral_left\", \"lateral_right\", \"hip_left\", \"hip_right\", \"head\"]\n",
    "        parts = self._extract_parts_dict(ctx, target_parts)\n",
    "\n",
    "        def dist(k1, k2):\n",
    "            p1, p2 = parts.get(k1), parts.get(k2)\n",
    "            if p1 is None or p2 is None: return zero()\n",
    "            return pd.Series(np.linalg.norm(p1 - p2, axis=1), index=ctx.idx, dtype=\"float32\")\n",
    "\n",
    "        def vel(k, n_frames):\n",
    "            p_pos = parts.get(k)\n",
    "            if p_pos is None: return zero()\n",
    "            s_x, s_y = pd.Series(p_pos[:,0], index=ctx.idx), pd.Series(p_pos[:,1], index=ctx.idx)\n",
    "            raw = self._speed_series(s_x, s_y)\n",
    "            return raw.rolling(self._scale(n_frames), min_periods=1, center=True).mean().astype(\"float32\")\n",
    "\n",
    "        # Distances\n",
    "        feats[\"aa_nose_tailbase_dist\"] = dist(\"nose\", \"tail_base\")\n",
    "        feats[\"aa_nose_bodycenter_dist\"] = dist(\"nose\", \"body_center\")\n",
    "        feats[\"a_body_width\"] = dist(\"lateral_left\", \"lateral_right\")\n",
    "        if feats[\"a_body_width\"].sum() == 0: # Fallback if laterals missing\n",
    "            feats[\"a_body_width\"] = dist(\"hip_left\", \"hip_right\")\n",
    "\n",
    "        # Angle\n",
    "        if parts.get(\"nose\") is not None and parts.get(\"tail_base\") is not None and parts.get(\"body_center\") is not None:\n",
    "            v1 = parts[\"nose\"] - parts[\"body_center\"]\n",
    "            v2 = parts[\"tail_base\"] - parts[\"body_center\"]\n",
    "            dot = np.sum(v1*v2, axis=1)\n",
    "            mag = np.linalg.norm(v1, axis=1) * np.linalg.norm(v2, axis=1)\n",
    "            feats[\"a_body_angle\"] = np.clip(dot/(mag+1e-6), -1.0, 1.0).astype(\"float32\")\n",
    "        else:\n",
    "            feats[\"a_body_angle\"] = zero()\n",
    "\n",
    "        # Part Velocities\n",
    "        for p in [\"nose\", \"tail_base\", \"ear_right\", \"head\"]:\n",
    "            if parts.get(p) is not None:\n",
    "                for t in [15, 30, 60, 90]: # 500ms, 1s, 2s, 3s\n",
    "                    feats[f\"a_{p}_vel_{int(t*1000/30)}ms\"] = vel(p, t)\n",
    "        \n",
    "        return feats\n",
    "\n",
    "    def _feat_pairwise(self, ctx: AgentContext, target_ctx: AgentContext=None, **kwargs) -> Dict:\n",
    "        if target_ctx is None: return {}\n",
    "        feats = {}\n",
    "        idx = ctx.idx\n",
    "        def zero(): return pd.Series(0.0, index=idx, dtype=\"float32\")\n",
    "\n",
    "        rel_vec = target_ctx.pos - ctx.pos\n",
    "        dist = np.linalg.norm(rel_vec, axis=1)\n",
    "        feats[\"rel_dist\"] = pd.Series(dist, index=idx, dtype=\"float32\")\n",
    "\n",
    "        # Detailed distances\n",
    "        my_parts = self._extract_parts_dict(ctx, [\"nose\", \"head\", \"tail_base\"])\n",
    "        t_parts = self._extract_parts_dict(target_ctx, [\"nose\", \"head\", \"tail_base\", \"body_center\", \"ear_left\", \"ear_right\", \"lateral_left\", \"lateral_right\", \"neck\", \"hip_left\", \"hip_right\"])\n",
    "\n",
    "        def dist_ab(pa, pb):\n",
    "            if pa is None or pb is None: return zero()\n",
    "            return pd.Series(np.linalg.norm(pa - pb, axis=1), index=idx, dtype=\"float32\")\n",
    "\n",
    "        mn = my_parts.get(\"nose\") if my_parts.get(\"nose\") is not None else my_parts.get(\"head\")\n",
    "        \n",
    "        feats[\"dist_nose_nose\"] = dist_ab(mn, t_parts.get(\"nose\"))\n",
    "        feats[\"dist_nose_tail\"] = dist_ab(mn, t_parts.get(\"tail_base\"))\n",
    "        feats[\"dist_nose_body\"] = dist_ab(mn, t_parts.get(\"body_center\"))\n",
    "        feats[\"dist_nose_el\"] = dist_ab(mn, t_parts.get(\"ear_left\"))\n",
    "        feats[\"dist_nose_er\"] = dist_ab(mn, t_parts.get(\"ear_right\"))\n",
    "        feats[\"dist_nose_neck\"] = dist_ab(mn, t_parts.get(\"neck\"))\n",
    "        feats[\"dist_nose_hip_l\"] = dist_ab(mn, t_parts.get(\"hip_left\"))\n",
    "        feats[\"dist_nose_hip_r\"] = dist_ab(mn, t_parts.get(\"hip_right\"))\n",
    "\n",
    "        # Angles\n",
    "        u_vec = rel_vec / (np.where(dist==0, 1e-6, dist)[:,None])\n",
    "        a_along = np.sum(ctx.vel * u_vec, axis=1)\n",
    "        t_along = np.sum(target_ctx.vel * (-u_vec), axis=1)\n",
    "        \n",
    "        feats[\"approach_speed_agent\"] = pd.Series(a_along, index=idx, dtype=\"float32\")\n",
    "        feats[\"approach_speed_target\"] = pd.Series(t_along, index=idx, dtype=\"float32\")\n",
    "        feats[\"approach_speed_rel\"] = pd.Series(np.sum((ctx.vel - target_ctx.vel)*u_vec, axis=1), index=idx, dtype=\"float32\")\n",
    "        feats[\"lateral_speed_agent\"] = pd.Series(np.linalg.norm(ctx.vel - (a_along[:,None]*u_vec), axis=1), index=idx, dtype=\"float32\")\n",
    "\n",
    "        # Body cosine\n",
    "        def get_vec(parts_dict):\n",
    "            h = parts_dict.get(\"nose\") or parts_dict.get(\"head\")\n",
    "            t = parts_dict.get(\"tail_base\") or parts_dict.get(\"body_center\")\n",
    "            if h is not None and t is not None: return h - t\n",
    "            return None\n",
    "        \n",
    "        va, vt = get_vec(my_parts), get_vec(t_parts)\n",
    "        if va is not None and vt is not None:\n",
    "            dot = np.sum(va * vt, axis=1)\n",
    "            mag = np.linalg.norm(va, axis=1) * np.linalg.norm(vt, axis=1)\n",
    "            feats[\"body_cosine\"] = pd.Series(np.clip(dot/(mag+1e-6), -1, 1), index=idx, dtype=\"float32\")\n",
    "        else:\n",
    "            feats[\"body_cosine\"] = zero()\n",
    "            \n",
    "        if va is not None:\n",
    "            dot_g = np.sum(va * rel_vec, axis=1)\n",
    "            mag_g = np.linalg.norm(va, axis=1) * dist\n",
    "            feats[\"gaze_cosine\"] = pd.Series(np.clip(dot_g/(mag_g+1e-6), -1, 1), index=idx, dtype=\"float32\")\n",
    "        else:\n",
    "            feats[\"gaze_cosine\"] = zero()\n",
    "\n",
    "        return feats\n",
    "\n",
    "    def _feat_shortburst_social(self, ctx: AgentContext, target_ctx: AgentContext=None, **kwargs) -> Dict:\n",
    "        if target_ctx is None: return {}\n",
    "        feats = {}\n",
    "        idx = ctx.idx\n",
    "        \n",
    "        rel_vec = target_ctx.pos - ctx.pos\n",
    "        dist = np.linalg.norm(rel_vec, axis=1)\n",
    "        u_vec = rel_vec / (np.where(dist==0, 1e-6, dist)[:,None])\n",
    "        a_along = np.sum(ctx.vel * u_vec, axis=1)\n",
    "        rel_along = np.sum((ctx.vel - target_ctx.vel) * u_vec, axis=1)\n",
    "        \n",
    "        # heading cos\n",
    "        parts = self._extract_parts_dict(ctx, [\"nose\", \"tail_base\", \"body_center\"])\n",
    "        head = parts.get(\"nose\")\n",
    "        tail = parts.get(\"tail_base\") or parts.get(\"body_center\")\n",
    "        heading_cos = np.zeros(len(idx), dtype=\"float32\")\n",
    "        if head is not None and tail is not None:\n",
    "            body = head - tail\n",
    "            dot = np.sum(body * rel_vec, axis=1)\n",
    "            mag = np.linalg.norm(body, axis=1) * dist\n",
    "            heading_cos = np.clip(dot/(mag+1e-6), -1, 1)\n",
    "        \n",
    "        s_along = pd.Series(a_along, index=idx)\n",
    "        s_rel = pd.Series(rel_along, index=idx)\n",
    "        s_dist = pd.Series(dist, index=idx)\n",
    "        s_head = pd.Series(heading_cos, index=idx)\n",
    "        \n",
    "        for w30 in [10, 20, 30]:\n",
    "            ws = self._scale(w30)\n",
    "            min_p = max(1, ws//3)\n",
    "            # Attack\n",
    "            feats[f\"sb_att_approach_mean_{w30}\"] = s_along.rolling(ws, min_periods=min_p).mean()\n",
    "            feats[f\"sb_att_rel_along_mean_{w30}\"] = s_rel.rolling(ws, min_periods=min_p).mean()\n",
    "            feats[f\"sb_att_dist_delta_{w30}\"] = (s_dist - s_dist.shift(ws)).fillna(0.0)\n",
    "            # Chase\n",
    "            feats[f\"sb_chase_speed_agent_mean_{w30}\"] = ctx.speed_series.rolling(ws, min_periods=min_p).mean()\n",
    "            feats[f\"sb_chase_speed_target_mean_{w30}\"] = target_ctx.speed_series.rolling(ws, min_periods=min_p).mean()\n",
    "            feats[f\"sb_chase_dist_mean_{w30}\"] = s_dist.rolling(ws, min_periods=min_p).mean()\n",
    "            # Escape\n",
    "            feats[f\"sb_esc_heading_cos_mean_{w30}\"] = s_head.rolling(ws, min_periods=min_p).mean()\n",
    "            feats[f\"sb_esc_dist_gain_{w30}\"] = (s_dist.shift(-ws) - s_dist).fillna(0.0)\n",
    "            \n",
    "        return {k: v.astype(\"float32\").fillna(0.0) for k,v in feats.items()}\n",
    "\n",
    "    def _feat_follow_pattern(self, ctx: AgentContext, target_ctx: AgentContext=None, **kwargs) -> Dict:\n",
    "        if target_ctx is None: return {}\n",
    "        feats = {}\n",
    "        idx = ctx.idx\n",
    "        dist = pd.Series(np.linalg.norm(target_ctx.pos - ctx.pos, axis=1), index=idx)\n",
    "        \n",
    "        # Cosines\n",
    "        parts_a = self._extract_parts_dict(ctx, [\"nose\", \"tail_base\", \"body_center\"])\n",
    "        parts_t = self._extract_parts_dict(target_ctx, [\"nose\", \"tail_base\", \"body_center\"])\n",
    "        \n",
    "        def bvec(p):\n",
    "            h = p.get(\"nose\"); t = p.get(\"tail_base\") or p.get(\"body_center\")\n",
    "            return (h-t) if (h is not None and t is not None) else None\n",
    "        \n",
    "        va, vt = bvec(parts_a), bvec(parts_t)\n",
    "        cos_body = np.zeros(len(idx), dtype=\"float32\")\n",
    "        if va is not None and vt is not None:\n",
    "            cos_body = np.clip(np.sum(va*vt, axis=1)/(np.linalg.norm(va, axis=1)*np.linalg.norm(vt, axis=1)+1e-6), -1, 1)\n",
    "            \n",
    "        dot_v = np.sum(ctx.vel * target_ctx.vel, axis=1)\n",
    "        mag_v = ctx.speed[:,0] * target_ctx.speed[:,0]\n",
    "        cos_vel = np.zeros_like(dot_v)\n",
    "        mask = mag_v > 1e-3\n",
    "        cos_vel[mask] = np.clip(dot_v[mask]/mag_v[mask], -1, 1)\n",
    "        \n",
    "        s_cb = pd.Series(cos_body, index=idx)\n",
    "        s_cv = pd.Series(cos_vel, index=idx)\n",
    "        \n",
    "        for w30 in [15, 30, 60]:\n",
    "            ws = self._scale(w30)\n",
    "            min_p = max(1, ws//3)\n",
    "            feats[f\"follow_dist_mean_{w30}\"] = dist.rolling(ws, min_periods=min_p).mean()\n",
    "            feats[f\"follow_dist_std_{w30}\"] = dist.rolling(ws, min_periods=min_p).std()\n",
    "            feats[f\"follow_cos_body_mean_{w30}\"] = s_cb.rolling(ws, min_periods=min_p).mean()\n",
    "            feats[f\"follow_cos_vel_mean_{w30}\"] = s_cv.rolling(ws, min_periods=min_p).mean()\n",
    "            feats[f\"follow_speed_agent_mean_{w30}\"] = ctx.speed_series.rolling(ws, min_periods=min_p).mean()\n",
    "            feats[f\"follow_speed_target_mean_{w30}\"] = target_ctx.speed_series.rolling(ws, min_periods=min_p).mean()\n",
    "            \n",
    "        return {k: v.fillna(0.0).astype(\"float32\") for k,v in feats.items()}\n",
    "\n",
    "    def _feat_climb(self, ctx: AgentContext, **kwargs) -> Dict:\n",
    "        # Hỗ trợ ElegantMink (Rect) và GroovyShrew\n",
    "        # Hardcode arena size based on labs usually seen in this comp\n",
    "        W, H = 33.0, 19.0 # Standard box size often used\n",
    "        \n",
    "        feats = {}\n",
    "        idx = ctx.idx\n",
    "        parts = self._extract_parts_dict(ctx, [\"nose\", \"head\", \"body_center\"])\n",
    "        head = parts.get(\"nose\") or parts.get(\"head\") or ctx.pos\n",
    "        \n",
    "        cx, cy = head[:,0], head[:,1]\n",
    "        \n",
    "        d_l, d_r = cx, W - cx\n",
    "        d_b, d_t = cy, H - cy\n",
    "        d_all = np.stack([d_l, d_r, d_b, d_t], axis=1)\n",
    "        dist_wall = np.min(d_all, axis=1)\n",
    "        wall_idx = np.argmin(d_all, axis=1) # 0:L, 1:R, 2:B, 3:T\n",
    "        \n",
    "        s_dw = pd.Series(dist_wall, index=idx, dtype=\"float32\")\n",
    "        feats[\"climb_dist_wall\"] = s_dw\n",
    "        \n",
    "        # Normal vector\n",
    "        nx, ny = np.zeros_like(cx), np.zeros_like(cy)\n",
    "        nx[wall_idx==0] = 1; nx[wall_idx==1] = -1\n",
    "        ny[wall_idx==2] = 1; ny[wall_idx==3] = -1\n",
    "        \n",
    "        vx, vy = ctx.vel[:,0], ctx.vel[:,1]\n",
    "        v_norm = vx*nx + vy*ny\n",
    "        v_tan = np.sqrt((vx - v_norm*nx)**2 + (vy - v_norm*ny)**2)\n",
    "        \n",
    "        feats[\"climb_normal_vel\"] = pd.Series(v_norm, index=idx, dtype=\"float32\")\n",
    "        feats[\"climb_tangent_vel\"] = pd.Series(v_tan, index=idx, dtype=\"float32\")\n",
    "        \n",
    "        # Stick score\n",
    "        ws = self._scale(15)\n",
    "        appr = -s_dw.diff().fillna(0.0).rolling(ws, min_periods=1).mean()\n",
    "        feats[\"climb_approach_speed_wall\"] = appr\n",
    "        \n",
    "        near = (dist_wall < 3.0).astype(float)\n",
    "        stick = near * (1.0 / (1.0 + np.abs(v_norm))) * (v_tan > 0.5)\n",
    "        feats[\"climb_wall_stick_score\"] = pd.Series(stick, index=idx, dtype=\"float32\")\n",
    "        \n",
    "        return feats\n",
    "\n",
    "    def _feat_ejaculate_temporal(self, ctx: AgentContext, target_ctx: AgentContext=None, **kwargs) -> Dict:\n",
    "        if target_ctx is None: return {}\n",
    "        idx = ctx.idx\n",
    "        parts_a = self._extract_parts_dict(ctx, [\"nose\", \"body_center\", \"tail_base\"])\n",
    "        parts_t = self._extract_parts_dict(target_ctx, [\"body_center\", \"tail_base\"])\n",
    "        \n",
    "        def dist(p1, p2):\n",
    "            if p1 is None or p2 is None: return pd.Series(0.0, index=idx)\n",
    "            return pd.Series(np.linalg.norm(p1-p2, axis=1), index=idx)\n",
    "        \n",
    "        abc = parts_a.get(\"body_center\") or parts_a.get(\"tail_base\") or ctx.pos\n",
    "        tbc = parts_t.get(\"body_center\") or parts_t.get(\"tail_base\") or target_ctx.pos\n",
    "        t_tail = parts_t.get(\"tail_base\") or tbc\n",
    "        \n",
    "        d_body = dist(abc, tbc)\n",
    "        d_gen = dist(abc, t_tail)\n",
    "        d_nose_gen = dist(parts_a.get(\"nose\"), t_tail)\n",
    "        \n",
    "        feats = {\n",
    "            \"ejac_dist_body\": d_body,\n",
    "            \"ejac_dist_gen_body\": d_gen,\n",
    "            \"ejac_dist_gen_nose\": d_nose_gen\n",
    "        }\n",
    "        \n",
    "        # Prox\n",
    "        prox = np.exp(-d_body.to_numpy()/5.0) * (1.0/(1.0+d_gen.to_numpy()))\n",
    "        \n",
    "        # Memory\n",
    "        v = ctx.speed_series\n",
    "        close = (d_body < 5.0).astype(float)\n",
    "        mem = (v*close).rolling(self._scale(90), min_periods=1).max().fillna(0.0)\n",
    "        feats[\"ejac_activity_memory_3s\"] = mem\n",
    "        \n",
    "        is_still = (v < 1.5).astype(float)\n",
    "        feats[\"ejac_is_still\"] = pd.Series(is_still, index=idx)\n",
    "        feats[\"ejac_static_score\"] = pd.Series(is_still * prox * mem, index=idx)\n",
    "        \n",
    "        return {k: v.astype(\"float32\") for k,v in feats.items()}\n",
    "\n",
    "    def _feat_submission_temporal(self, ctx: AgentContext, target_ctx: AgentContext=None, **kwargs) -> Dict:\n",
    "        if target_ctx is None: return {}\n",
    "        idx = ctx.idx\n",
    "        rel = target_ctx.pos - ctx.pos\n",
    "        dist = np.linalg.norm(rel, axis=1)\n",
    "        dist_s = pd.Series(dist, index=idx).replace(0, 1e-6)\n",
    "        \n",
    "        dot = np.sum(target_ctx.vel * (-rel), axis=1)\n",
    "        threat = (dot / dist_s).clip(lower=0) * (dist_s < 15.0).astype(float)\n",
    "        \n",
    "        mem = threat.rolling(self._scale(90), min_periods=1).max().fillna(0.0)\n",
    "        \n",
    "        is_still = (ctx.speed_series < 1.0).astype(float)\n",
    "        \n",
    "        parts = self._extract_parts_dict(ctx, [\"nose\", \"tail_base\"])\n",
    "        compact = pd.Series(0.0, index=idx)\n",
    "        if parts.get(\"nose\") is not None and parts.get(\"tail_base\") is not None:\n",
    "            slen = np.linalg.norm(parts[\"nose\"] - parts[\"tail_base\"], axis=1)\n",
    "            compact = pd.Series((slen < 8.0).astype(float), index=idx)\n",
    "            \n",
    "        return {\n",
    "            \"fear_memory_3s\": mem.astype(\"float32\"),\n",
    "            \"static_submit_prob\": (is_still * compact * mem).astype(\"float32\")\n",
    "        }\n",
    "\n",
    "    def _feat_attack_sniff(self, ctx: AgentContext, target_ctx: AgentContext=None, **kwargs) -> Dict:\n",
    "        if target_ctx is None: return {}\n",
    "        idx = ctx.idx\n",
    "        feats = {}\n",
    "        \n",
    "        # Violence\n",
    "        ws = self._scale(15)\n",
    "        mp = max(1, ws//3)\n",
    "        va = ctx.speed_series.rolling(ws, min_periods=mp).std().fillna(0.0)\n",
    "        vt = target_ctx.speed_series.rolling(ws, min_periods=mp).std().fillna(0.0)\n",
    "        feats[\"as_speed_std_sum_05\"] = (va + vt).astype(\"float32\")\n",
    "        \n",
    "        # Jerk (Turn)\n",
    "        ang = np.arctan2(ctx.vel[:,1], ctx.vel[:,0])\n",
    "        diff = np.abs(np.diff(ang, prepend=ang[0]))\n",
    "        diff = np.where(diff > np.pi, 2*np.pi - diff, diff)\n",
    "        feats[\"as_a_turn_jerk_05\"] = pd.Series(diff, index=idx).rolling(ws, min_periods=mp).sum().fillna(0.0).astype(\"float32\")\n",
    "        \n",
    "        # BBox IoU (Quan trọng cho attack)\n",
    "        def get_bbox(c, p_list):\n",
    "            arrs = []\n",
    "            parts = self._extract_parts_dict(c, p_list)\n",
    "            for k in p_list:\n",
    "                if parts.get(k) is not None: arrs.append(parts[k])\n",
    "            if not arrs: return None\n",
    "            st = np.stack(arrs, axis=1)\n",
    "            return np.stack([np.nanmin(st[...,0],1), np.nanmin(st[...,1],1), np.nanmax(st[...,0],1), np.nanmax(st[...,1],1)], axis=1)\n",
    "            \n",
    "        plist = [\"nose\", \"tail_base\", \"neck\", \"hip_left\", \"hip_right\", \"head\"]\n",
    "        b1 = get_bbox(ctx, plist)\n",
    "        b2 = get_bbox(target_ctx, plist)\n",
    "        \n",
    "        iou = np.zeros(len(idx), dtype=\"float32\")\n",
    "        if b1 is not None and b2 is not None:\n",
    "            xA = np.maximum(b1[:,0], b2[:,0])\n",
    "            yA = np.maximum(b1[:,1], b2[:,1])\n",
    "            xB = np.minimum(b1[:,2], b2[:,2])\n",
    "            yB = np.minimum(b1[:,3], b2[:,3])\n",
    "            inter = np.maximum(0, xB-xA) * np.maximum(0, yB-yA)\n",
    "            a1 = (b1[:,2]-b1[:,0])*(b1[:,3]-b1[:,1])\n",
    "            a2 = (b2[:,2]-b2[:,0])*(b2[:,3]-b2[:,1])\n",
    "            iou = inter / (a1 + a2 - inter + 1e-6)\n",
    "            \n",
    "        feats[\"as_body_iou\"] = pd.Series(iou, index=idx, dtype=\"float32\")\n",
    "        return feats\n",
    "\n",
    "    def _feat_attack_defend(self, ctx: AgentContext, target_ctx: AgentContext=None, **kwargs) -> Dict:\n",
    "        # Alias or subset of attack_sniff logic often used in Robustify\n",
    "        return self._feat_attack_sniff(ctx, target_ctx)\n",
    "\n",
    "    def build_pose_tensor(self, tracking: pd.DataFrame):\n",
    "        tracking = tracking.sort_values(\"video_frame\")\n",
    "        frames = np.sort(tracking[\"video_frame\"].unique())\n",
    "        \n",
    "        pvid = tracking.pivot(index=\"video_frame\", columns=[\"mouse_id\", \"bodypart\"], values=[\"x\", \"y\"])\n",
    "        pvid = pvid.reorder_levels([1, 2, 0], axis=1).sort_index(axis=1).astype(\"float32\")\n",
    "        \n",
    "        mouse_ids = list(pvid.columns.get_level_values(0).unique())\n",
    "        pos = np.full((len(frames), len(mouse_ids), 2), np.nan, dtype=np.float32)\n",
    "        per_mouse_df = {}\n",
    "        \n",
    "        for i, mid in enumerate(mouse_ids):\n",
    "            single = pvid[mid]\n",
    "            per_mouse_df[mid] = single\n",
    "            \n",
    "            # Ưu tiên body_center, nếu không có thì lấy trung bình\n",
    "            if \"body_center\" in single.columns.get_level_values(0):\n",
    "                cx = single[\"body_center\"][\"x\"]\n",
    "                cy = single[\"body_center\"][\"y\"]\n",
    "            else:\n",
    "                cx = single.xs(\"x\", level=1, axis=1).mean(axis=1)\n",
    "                cy = single.xs(\"y\", level=1, axis=1).mean(axis=1)\n",
    "                \n",
    "            pos[:, i, 0] = cx.reindex(frames).values\n",
    "            pos[:, i, 1] = cy.reindex(frames).values\n",
    "            \n",
    "        return frames, mouse_ids, pos, per_mouse_df\n",
    "\n",
    "    def extract_agent_target(self, frames, mouse_ids, pos, agent_id, target_id, per_mouse_df=None):\n",
    "        try:\n",
    "            aid_idx = mouse_ids.index(agent_id)\n",
    "        except ValueError:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        ctx_agent = self._build_context(frames, pos[:, aid_idx, :], per_mouse_df.get(agent_id) if per_mouse_df else None)\n",
    "        \n",
    "        ctx_target = None\n",
    "        if self.cfg.use_pairwise and target_id in mouse_ids:\n",
    "            tid_idx = mouse_ids.index(target_id)\n",
    "            ctx_target = self._build_context(frames, pos[:, tid_idx, :], per_mouse_df.get(target_id) if per_mouse_df else None)\n",
    "\n",
    "        all_data = {}\n",
    "        for name, func in self.feature_registry.items():\n",
    "            # Chạy tất cả feature, bỏ qua lỗi (do thiếu part) để code chạy bền vững\n",
    "            try:\n",
    "                out = func(ctx_agent, target_ctx=ctx_target)\n",
    "                all_data.update(out)\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        df_out = pd.DataFrame(all_data, index=ctx_agent.idx)\n",
    "        # Final cleanup: fill inf/nan và sort columns\n",
    "        return df_out.replace([np.inf, -np.inf], np.nan).fillna(0.0).reindex(sorted(df_out.columns), axis=1)\n",
    "\n",
    "# =============================================================================\n",
    "# 2. INFERENCE LOOP\n",
    "# =============================================================================\n",
    "\n",
    "def predict_lab_video(lab_id, video_id, test_meta, result_dir):\n",
    "    # 1. Load Data\n",
    "    try:\n",
    "        tr_path = TEST_TRACKING_DIR / str(lab_id) / f\"{video_id}.parquet\"\n",
    "        if not tr_path.exists(): return []\n",
    "        tracking = pd.read_parquet(tr_path)\n",
    "    except: return []\n",
    "\n",
    "    # 2. Setup Feature Extractor\n",
    "    row = test_meta[test_meta[\"video_id\"] == video_id].iloc[0]\n",
    "    fps = float(row[\"frames_per_second\"])\n",
    "    pix = float(row[\"pix_per_cm_approx\"]) if row[\"pix_per_cm_approx\"] > 0 else 1.0\n",
    "    \n",
    "    fe = FeatureExtractor(fps=fps, pix_per_cm=pix)\n",
    "    frames, mouse_ids, pos, per_mouse_df = fe.build_pose_tensor(tracking)\n",
    "    \n",
    "    # 3. Xác định behaviors cần predict\n",
    "    lab_res_path = result_dir / lab_id\n",
    "    if not lab_res_path.exists(): return []\n",
    "    \n",
    "    available_bhvs = [p.name for p in lab_res_path.iterdir() if p.is_dir()]\n",
    "    self_b = [b for b in available_bhvs if b in SELF_BEHAVIORS]\n",
    "    pair_b = [b for b in available_bhvs if b in PAIR_BEHAVIORS]\n",
    "    \n",
    "    preds = []\n",
    "    \n",
    "    # Helper: Load Models (Cache nếu cần, ở đây load thẳng cho đơn giản)\n",
    "    def run_inference(feat_df, behavior):\n",
    "        bhv_dir = lab_res_path / behavior\n",
    "        # Load weights/threshold\n",
    "        ws, th = {}, 0.5\n",
    "        if (bhv_dir / \"ensemble_params.json\").exists():\n",
    "            with open(bhv_dir / \"ensemble_params.json\") as f: \n",
    "                d = json.load(f)\n",
    "                ws, th = d.get(\"weights\", {}), d.get(\"threshold\", 0.5)\n",
    "        \n",
    "        # Load models\n",
    "        models = []\n",
    "        for fd in sorted(bhv_dir.glob(\"fold_*\")):\n",
    "            m_set = {}\n",
    "            # XGB\n",
    "            if (fd/\"model_xgb.json\").exists():\n",
    "                b = xgb.Booster()\n",
    "                b.load_model(str(fd/\"model_xgb.json\"))\n",
    "                m_set[\"xgb\"] = b\n",
    "            elif (fd/\"model.json\").exists(): # Fallback naming\n",
    "                b = xgb.Booster()\n",
    "                b.load_model(str(fd/\"model.json\"))\n",
    "                m_set[\"xgb\"] = b\n",
    "            \n",
    "            # Cat/LGB (nếu có)\n",
    "            if (fd/\"model_cat.cbm\").exists():\n",
    "                c = cb.CatBoostClassifier()\n",
    "                c.load_model(str(fd/\"model_cat.cbm\"))\n",
    "                m_set[\"cat\"] = c\n",
    "            if (fd/\"model_lgb.txt\").exists():\n",
    "                l = lgb.Booster(model_file=str(fd/\"model_lgb.txt\"))\n",
    "                m_set[\"lgb\"] = l\n",
    "            \n",
    "            if m_set: models.append(m_set)\n",
    "            \n",
    "        if not models: return None\n",
    "        \n",
    "        # Prepare Data\n",
    "        # Quan trọng: Chỉ lấy các cột model cần\n",
    "        req_cols = []\n",
    "        if \"xgb\" in models[0]: req_cols = models[0][\"xgb\"].feature_names\n",
    "        \n",
    "        if not req_cols: req_cols = feat_df.columns.tolist()\n",
    "        \n",
    "        # Tạo X đúng thứ tự cột\n",
    "        X = pd.DataFrame(0.0, index=feat_df.index, columns=req_cols, dtype=np.float32)\n",
    "        common = list(set(req_cols) & set(feat_df.columns))\n",
    "        X[common] = feat_df[common]\n",
    "        \n",
    "        dtest = xgb.DMatrix(X, feature_names=req_cols)\n",
    "        \n",
    "        # Predict & Ensemble\n",
    "        final_prob = np.zeros(len(X), dtype=np.float32)\n",
    "        for m in models:\n",
    "            p = 0\n",
    "            if \"xgb\" in m: p += m[\"xgb\"].predict(dtest) * ws.get(\"xgb\", 1.0)\n",
    "            if \"cat\" in m: p += m[\"cat\"].predict_proba(X)[:,1] * ws.get(\"cat\", 0.33)\n",
    "            if \"lgb\" in m: p += m[\"lgb\"].predict(X) * ws.get(\"lgb\", 0.33)\n",
    "            \n",
    "            # Normalize weight sum if needed, here assuming simple avg or dominated by xgb\n",
    "            final_prob += p\n",
    "            \n",
    "        final_prob /= len(models)\n",
    "        return (final_prob >= th).astype(\"int8\")\n",
    "\n",
    "    def fid(mid): return str(mid) if str(mid).startswith(\"mouse\") else f\"mouse{mid}\"\n",
    "\n",
    "    # --- SELF LOOP ---\n",
    "    for m in mouse_ids:\n",
    "        fdf = fe.extract_features(frames, mouse_ids, pos, per_mouse_df, m, m)\n",
    "        if fdf.empty: continue\n",
    "        for bhv in self_b:\n",
    "            mask = run_inference(fdf, bhv)\n",
    "            if mask is None: continue\n",
    "            \n",
    "            # RLE to segments\n",
    "            # (Simple 1-pass)\n",
    "            on = False\n",
    "            start = 0\n",
    "            for i, v in enumerate(mask):\n",
    "                if v and not on:\n",
    "                    on = True; start = frames[i]\n",
    "                elif not v and on:\n",
    "                    on = False\n",
    "                    preds.append([video_id, fid(m), \"self\", bhv, int(start), int(frames[i])])\n",
    "            if on: preds.append([video_id, fid(m), \"self\", bhv, int(start), int(frames[-1])+1])\n",
    "\n",
    "    # --- PAIR LOOP ---\n",
    "    if len(mouse_ids) > 1:\n",
    "        for a, t in itertools.permutations(mouse_ids, 2):\n",
    "            fdf = fe.extract_features(frames, mouse_ids, pos, per_mouse_df, a, t)\n",
    "            if fdf.empty: continue\n",
    "            for bhv in pair_b:\n",
    "                mask = run_inference(fdf, bhv)\n",
    "                if mask is None: continue\n",
    "                \n",
    "                on = False\n",
    "                start = 0\n",
    "                for i, v in enumerate(mask):\n",
    "                    if v and not on:\n",
    "                        on = True; start = frames[i]\n",
    "                    elif not v and on:\n",
    "                        on = False\n",
    "                        preds.append([video_id, fid(a), fid(t), bhv, int(start), int(frames[i])])\n",
    "                if on: preds.append([video_id, fid(a), fid(t), bhv, int(start), int(frames[-1])+1])\n",
    "                \n",
    "    return preds\n",
    "\n",
    "# =============================================================================\n",
    "# 3. MAIN RUN\n",
    "# =============================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=== STARTING INFERENCE (CORRECTED MAPPING) ===\")\n",
    "    \n",
    "    # Cleanup\n",
    "    for p in WORKING_DIR.iterdir():\n",
    "        if p.is_file() and p.suffix != \".csv\": p.unlink()\n",
    "        elif p.is_dir(): import shutil; shutil.rmtree(p)\n",
    "        \n",
    "    test_meta = pd.read_csv(INPUT_DIR / \"test.csv\")\n",
    "    all_rows = []\n",
    "    \n",
    "    for lab in TARGET_LABS:\n",
    "        print(f\"\\n>> Processing Lab: {lab}\")\n",
    "        # Lấy dir theo map, nếu không có trong map thì dùng default\n",
    "        res_dir = LAB_RESULT_DIR_MAP.get(lab, DEFAULT_RESULT_DIR)\n",
    "        print(f\"   Using models from: {res_dir}\")\n",
    "        \n",
    "        lab_meta = test_meta[test_meta[\"lab_id\"] == lab]\n",
    "        if lab_meta.empty: continue\n",
    "        \n",
    "        for vid in sorted(lab_meta[\"video_id\"].unique()):\n",
    "            try:\n",
    "                p = predict_lab_video(lab, vid, test_meta, res_dir)\n",
    "                all_rows.extend(p)\n",
    "            except Exception as e:\n",
    "                print(f\"   Err {vid}: {e}\")\n",
    "            gc.collect()\n",
    "            \n",
    "    # Save\n",
    "    cols = [\"video_id\", \"agent_id\", \"target_id\", \"action\", \"start_frame\", \"stop_frame\"]\n",
    "    if all_rows:\n",
    "        sub = pd.DataFrame(all_rows, columns=cols)\n",
    "        sub = sub.sort_values([\"video_id\", \"agent_id\", \"target_id\", \"action\", \"start_frame\"])\n",
    "        sub.insert(0, \"row_id\", np.arange(len(sub)))\n",
    "    else:\n",
    "        sub = pd.DataFrame(columns=[\"row_id\"] + cols)\n",
    "        \n",
    "    sub.to_csv(WORKING_DIR / \"submission.csv\", index=False)\n",
    "    print(f\"\\nDone! Saved {len(sub)} rows to submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 13874099,
     "sourceId": 59156,
     "sourceType": "competition"
    },
    {
     "datasetId": 8619229,
     "sourceId": 13607639,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1415.401673,
   "end_time": "2025-11-16T09:35:19.404828",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-16T09:11:44.003155",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "00962fe9010e42b7a5b123af50d2a026": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0b098fa23a3b4031bf88b32b20044978": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "108c3e5db1154f47a5aca68386ed4f24": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "38c36db3be3843b19da108d4cd1f9421": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_3e9806911d1d489d963f76955d8468c4",
        "IPY_MODEL_e6ad60bc760e4b51885b15335c048a65",
        "IPY_MODEL_6f4723180bf14101b60deeac9fd59e50"
       ],
       "layout": "IPY_MODEL_00962fe9010e42b7a5b123af50d2a026",
       "tabbable": null,
       "tooltip": null
      }
     },
     "3e9806911d1d489d963f76955d8468c4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_aeb2544f9ad9413b8b71b5f5643b1019",
       "placeholder": "​",
       "style": "IPY_MODEL_ec012e9ac53d477daee0988a35117f0b",
       "tabbable": null,
       "tooltip": null,
       "value": "100%"
      }
     },
     "3edd91e1eafb4f6bbf55275ea60b6c97": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6f4723180bf14101b60deeac9fd59e50": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e8f95c8096294ce6b6fb2b65c08af536",
       "placeholder": "​",
       "style": "IPY_MODEL_0b098fa23a3b4031bf88b32b20044978",
       "tabbable": null,
       "tooltip": null,
       "value": " 863/863 [00:08&lt;00:00, 96.46it/s]"
      }
     },
     "aeb2544f9ad9413b8b71b5f5643b1019": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e6ad60bc760e4b51885b15335c048a65": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3edd91e1eafb4f6bbf55275ea60b6c97",
       "max": 863,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_108c3e5db1154f47a5aca68386ed4f24",
       "tabbable": null,
       "tooltip": null,
       "value": 863
      }
     },
     "e8f95c8096294ce6b6fb2b65c08af536": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ec012e9ac53d477daee0988a35117f0b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
